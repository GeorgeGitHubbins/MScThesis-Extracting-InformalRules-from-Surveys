{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from cohere import ClassifyExample\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "cohereKey = \"YPOV5Eud45eYSDtQUxsHUERJVWwHGXotsogyzH5j\"\n",
    "co = cohere.Client(cohereKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "def replace_not_numbered(row):\n",
    "    if row[\"Question number\\n (Questionnaire file)\"] == \"not numbered\":\n",
    "        return row[\"Variable Label\\n (Data files)\"]\n",
    "    else:\n",
    "        return row[\"Question number\\n (Questionnaire file)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_questions  = pd.read_excel('Survey Questions Overview.xlsx', sheet_name='Wave 1', engine='openpyxl')\n",
    "# Clean the survey questions dataframe to make it more usable for mapping\n",
    "# Fill forward non-null ADICO Category values to apply them to all relevant rows, Specify the columns to forward fill excluding \"Values\" and \"Value labels\"\n",
    "columns_to_ffill = [col for col in survey_questions.columns if col not in [\"Values\", \"Value labels\"]]\n",
    "\n",
    "# Forward fill the specified columns\n",
    "survey_questions[columns_to_ffill] = survey_questions[columns_to_ffill].ffill()\n",
    "\n",
    "\n",
    "# Apply the function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "survey_questions[\"Question number\\n (Questionnaire file)\"] = survey_questions.apply(replace_not_numbered, axis=1)\n",
    "\n",
    "\n",
    "# Set the index to {value of \"Question number\\n (Questionnaire file)\"} + \"_\" + {str(value of \"Values\")}\n",
    "survey_questions.set_index(survey_questions[\"Variable Label\\n (Data files)\"] + \"_\" + survey_questions[\"Values\"].astype(str), inplace=True)\n",
    "survey_questions.drop(\"ID_nan\", inplace=True)\n",
    "\n",
    "question_answers_list = []\n",
    "# Define a function to create the combined string\n",
    "def combine_description_and_labels(group, question_answers_list, qnum):\n",
    "    question_subset = survey_questions[survey_questions[\"Question number\\n (Questionnaire file)\"] == group[\"Question number\\n (Questionnaire file)\"].iloc[0]]\n",
    "    # Check if it's the first row instance with the current \"Question number\\n (Questionnaire file)\" column value\n",
    "    first_instance_index = question_subset[question_subset.duplicated(subset=[\"Question number\\n (Questionnaire file)\"], keep=\"first\")].index\n",
    "    combined_string = \"\"\n",
    "    if first_instance_index.size != 0:\n",
    "        first_description = question_subset[\"Description\"].iloc[0]\n",
    "        if first_description != group[\"Description\"].iloc[0]:\n",
    "         # If not the first instance, start with the first instance's \"Description\" column value\n",
    "            combined_string += first_description\n",
    "    # Concatenate the current row's \"Description\" and all \"Value labels\" values\n",
    "    combined_string += str(group[\"Description\"].iloc[0])# + \" \" + \"; \".join(group[\"Value labels\"].astype(str))\n",
    "    question_answers_list = question_answers_list + [combined_string] * group.shape[0]  # Extend the list with the combined strings\n",
    "    return question_answers_list\n",
    "\n",
    "# Group by \"Variable Label\\n (Data files)\" and apply the function to create the combined string\n",
    "for group in survey_questions.groupby(\"Variable Label\\n (Data files)\",sort=False):\n",
    "    question_answers_list = combine_description_and_labels(group[1], question_answers_list, group[1][\"Question number\\n (Questionnaire file)\"].iloc[0])\n",
    "survey_questions[\"question_answers_combined\"] = question_answers_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming survey_questions is your DataFrame\n",
    "examples = []\n",
    "\n",
    "for label in survey_questions['ADICO Category'].unique():\n",
    "    for index, row in survey_questions[survey_questions['ADICO Category'] ==  label].sample(5).iterrows():\n",
    "        text = row['question_answers_combined']\n",
    "        examples.append(ClassifyExample(text=text, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset has multiple rows per question for different value labels, we'll create a unique mapping\n",
    "# Create the new mapping dictionary\n",
    "question_adico_mapping = survey_questions[['question_answers_combined','ADICO Category',\"Variable Label\\n (Data files)\"]].drop_duplicates().set_index('question_answers_combined')['ADICO Category']\n",
    "\n",
    "\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "attributes = [k for k, v in question_adico_mapping.items() if 'Attribute' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "conditions = [k for k, v in question_adico_mapping.items() if 'Condition' in str(v) or 'Aim/Condition' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "aims = [k for k, v in question_adico_mapping.items() if 'Aim' in str(v) or 'Aim/Condition' in str(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now we make a random selection of questions with assigned ADICO components but later we can provide the model with a predetermined selection\n",
    "selected_attributes = random.sample(attributes, 3)\n",
    "selected_conditions = random.sample(conditions, 3)\n",
    "selected_aims = random.sample(aims, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What category best describes your current home or accommodation?\n",
      "Classification: Potential Shared Strategy \n",
      "Text: Employment status\n",
      "Classification: Attribute\n",
      "Text: Zipcode or postal code\n",
      "Classification: Attribute\n"
     ]
    }
   ],
   "source": [
    "sampleinput = selected_attributes\n",
    "response = co.classify(\n",
    "  inputs=sampleinput,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "for classification in response.classifications:\n",
    "    print(\"Text:\", classification.input)\n",
    "    print(\"Classification:\", classification.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: End of section G\n",
      "Classification: Attribute\n",
      "Text: Too tired after work to enjoy things like doing at home, how often\n",
      "Classification: Condition\n",
      "Text: Ever belonging to particular religion or denomination\n",
      "Classification: Attribute\n",
      "Text: Partner's highest level of education, North Macedonia\n",
      "Classification: Attribute\n",
      "Text: Highest level of education, France\n",
      "Classification: Attribute\n"
     ]
    }
   ],
   "source": [
    "#Try for ESS Questions\n",
    "ESSQuestionData = pd.read_csv('ESSQuestionData.csv')\n",
    "ESS_Sample = list(ESSQuestionData['questiontext'].sample(5))\n",
    "\n",
    "response = co.classify(\n",
    "  inputs=ESS_Sample,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "for classification in response.classifications:\n",
    "    print(\"Text:\", classification.input)\n",
    "    print(\"Classification:\", classification.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the prompt\n",
    "prompt = \"Generate an Institutional shared strategy statement using all of the following sets of questions and answers containing Aims and Conditions:\\n\\n\"\n",
    "prompt += \"Aims:\\n\" + \"\\n\".join(selected_aims) + \"\\n\\n\"\n",
    "prompt += \"Conditions:\\n\" + \"\\n\".join(selected_conditions) + \"\\n\\n\"\n",
    "\n",
    "#Explain to the GPT what their role is:\n",
    "systemMessage = \"You are a helpful assistant that converts questions and answers from surveys into Institutional Behaviour Statements. You always output a list of statements that follow the following JSON structure: \\n\\n\"\n",
    "systemMessage += '{\"statements\":[\"Attribute\":\"Households in the Netherlands\", \"Aim\":\"do {Aim}\", \"Condition\":\"if {Condition(s)}]\"”\"\\n\\n\"'\n",
    "systemMessage += \"Your output will be read using the following: converted_questions = json.loads(response.choices[0].message.content) and converted_questions = pd.DataFrame(converted_questions_json['statements']).\"\n",
    "\n",
    "#Give them some context information:\n",
    "contentMessage = \"An institutional statement refers to a structured representation of institutions using specific elements such as Attribute, Deontic, Aim, Condition, and Or Else (ADICO). These statements are used to define and understand the impacts, actions, and conditions associated with institutional rules, norms, and shared strategies within social systems.\\n\\n\" \n",
    "contentMessage += \"Attribute: Who or what the impacts of the institution apply to, e.g. “Households in Indonesia” or “police officers”.\\n\\n\" \n",
    "contentMessage += \"Aim: The definition of the impact that is applied or the action performed, e.g. “reinforce their foundations bi-yearly” or “close the door”.\\n\\n\"\n",
    "contentMessage += \"Condition: the conditions that need to be satisfied in order for the aim to occur, e.g. “if they live with more than four people” or “if the alarm goes off”\\n\\n\"\n",
    "contentMessage += \"Combining all these elements produces the following Institutional shared strategy: “Police officers (Attribute) lock the doors of their vehicle (Aim) if they leave the vehicle (Condition)”'\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpreamble\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msystemMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cohere\\client.py:33\u001b[0m, in \u001b[0;36mvalidate_args.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m     32\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cohere\\base_client.py:669\u001b[0m, in \u001b[0;36mBaseCohere.chat\u001b[1;34m(self, message, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, tools, tool_results, request_options)\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(NonStreamedChatResponse, construct_type(type_\u001b[38;5;241m=\u001b[39mNonStreamedChatResponse, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequestsError(\n\u001b[0;32m    670\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    671\u001b[0m     )\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    673\u001b[0m     _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mTooManyRequestsError\u001b[0m: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}"
     ]
    }
   ],
   "source": [
    "response = co.chat(\n",
    "  preamble = systemMessage,\n",
    "  message=prompt,\n",
    "  model=\"command\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Aim</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>do regularly read information about flooding a...</td>\n",
       "      <td>if they believe that implementing non-structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>are more likely to consider implementing non-s...</td>\n",
       "      <td>if they perceive the damage to their house fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>are willing to purchase sandbags or other wate...</td>\n",
       "      <td>if they believe that this measure is affordabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Attribute  \\\n",
       "0  Households affected by the 2020 Jakarta Flood   \n",
       "1  Households affected by the 2020 Jakarta Flood   \n",
       "2  Households affected by the 2020 Jakarta Flood   \n",
       "\n",
       "                                                 Aim  \\\n",
       "0  do regularly read information about flooding a...   \n",
       "1  are more likely to consider implementing non-s...   \n",
       "2  are willing to purchase sandbags or other wate...   \n",
       "\n",
       "                                           Condition  \n",
       "0  if they believe that implementing non-structur...  \n",
       "1  if they perceive the damage to their house fro...  \n",
       "2  if they believe that this measure is affordabl...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse JSON\n",
    "converted_questions_json = json.loads(response.text.replace('```json\\n', '').replace('```', ''))\n",
    "\n",
    "# Convert JSON to dataframe\n",
    "converted_questions = pd.DataFrame(converted_questions_json[\"statements\"])\n",
    "\n",
    "# Display dataframe\n",
    "converted_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to Check the current prompt and categorize it\n",
    "def TaskInterpreter(response):\n",
    "    \n",
    "    # preamble containing instructions about the task and the desired style for the output.\n",
    "    preamble = \"\"\"\n",
    "    ## Task & Context\n",
    "    You read responses from llm agents and determine the type of task. You only output one of following options: \"Fix\", \"Write\", or \"Run\".\n",
    "\n",
    "    ## Definitions\n",
    "    Write: The message indicates that a script should be written\n",
    "    Fix: The message indicates that a change should be made to the script\n",
    "    Run: The message contains a python script that should be run and tested\n",
    "\n",
    "    ## Style Guide\n",
    "    You can only output a single word.\n",
    "    \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "    message=response,\n",
    "    preamble=preamble,\n",
    "    model=\"command\"\n",
    "    )\n",
    "    return response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
