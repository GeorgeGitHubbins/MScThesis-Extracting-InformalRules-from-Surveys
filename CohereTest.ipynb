{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from cohere import ClassifyExample\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "cohereKey = \"YPOV5Eud45eYSDtQUxsHUERJVWwHGXotsogyzH5j\"\n",
    "co = cohere.Client(cohereKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "def replace_not_numbered(row):\n",
    "    if row[\"Question number\\n (Questionnaire file)\"] == \"not numbered\":\n",
    "        return row[\"Variable Label\\n (Data files)\"]\n",
    "    else:\n",
    "        return row[\"Question number\\n (Questionnaire file)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_questions  = pd.read_excel('Survey Questions Overview.xlsx', sheet_name='Wave 1', engine='openpyxl')\n",
    "# Clean the survey questions dataframe to make it more usable for mapping\n",
    "# Fill forward non-null ADICO Category values to apply them to all relevant rows, Specify the columns to forward fill excluding \"Values\" and \"Value labels\"\n",
    "columns_to_ffill = [col for col in survey_questions.columns if col not in [\"Values\", \"Value labels\"]]\n",
    "\n",
    "# Forward fill the specified columns\n",
    "survey_questions[columns_to_ffill] = survey_questions[columns_to_ffill].ffill()\n",
    "\n",
    "\n",
    "# Apply the function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "survey_questions[\"Question number\\n (Questionnaire file)\"] = survey_questions.apply(replace_not_numbered, axis=1)\n",
    "\n",
    "\n",
    "# Set the index to {value of \"Question number\\n (Questionnaire file)\"} + \"_\" + {str(value of \"Values\")}\n",
    "survey_questions.set_index(survey_questions[\"Variable Label\\n (Data files)\"] + \"_\" + survey_questions[\"Values\"].astype(str), inplace=True)\n",
    "survey_questions.drop(\"ID_nan\", inplace=True)\n",
    "\n",
    "question_answers_list = []\n",
    "# Define a function to create the combined string\n",
    "def combine_description_and_labels(group, question_answers_list, qnum):\n",
    "    question_subset = survey_questions[survey_questions[\"Question number\\n (Questionnaire file)\"] == group[\"Question number\\n (Questionnaire file)\"].iloc[0]]\n",
    "    # Check if it's the first row instance with the current \"Question number\\n (Questionnaire file)\" column value\n",
    "    first_instance_index = question_subset[question_subset.duplicated(subset=[\"Question number\\n (Questionnaire file)\"], keep=\"first\")].index\n",
    "    combined_string = \"\"\n",
    "    if first_instance_index.size != 0:\n",
    "        first_description = question_subset[\"Description\"].iloc[0]\n",
    "        if first_description != group[\"Description\"].iloc[0]:\n",
    "         # If not the first instance, start with the first instance's \"Description\" column value\n",
    "            combined_string += first_description\n",
    "    # Concatenate the current row's \"Description\" and all \"Value labels\" values\n",
    "    combined_string += str(group[\"Description\"].iloc[0])# + \" \" + \"; \".join(group[\"Value labels\"].astype(str))\n",
    "    question_answers_list = question_answers_list + [combined_string] * group.shape[0]  # Extend the list with the combined strings\n",
    "    return question_answers_list\n",
    "\n",
    "# Group by \"Variable Label\\n (Data files)\" and apply the function to create the combined string\n",
    "for group in survey_questions.groupby(\"Variable Label\\n (Data files)\",sort=False):\n",
    "    question_answers_list = combine_description_and_labels(group[1], question_answers_list, group[1][\"Question number\\n (Questionnaire file)\"].iloc[0])\n",
    "survey_questions[\"question_answers_combined\"] = question_answers_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming survey_questions is your DataFrame\n",
    "examples = []\n",
    "\n",
    "for label in survey_questions['ADICO Category'].unique():\n",
    "    for index, row in survey_questions[survey_questions['ADICO Category'] ==  label].sample(5).iterrows():\n",
    "        text = row['question_answers_combined']\n",
    "        examples.append(ClassifyExample(text=text, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset has multiple rows per question for different value labels, we'll create a unique mapping\n",
    "# Create the new mapping dictionary\n",
    "question_adico_mapping = survey_questions[['question_answers_combined','ADICO Category',\"Variable Label\\n (Data files)\"]].drop_duplicates().set_index('question_answers_combined')['ADICO Category']\n",
    "\n",
    "\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "attributes = [k for k, v in question_adico_mapping.items() if 'Attribute' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "conditions = [k for k, v in question_adico_mapping.items() if 'Condition' in str(v) or 'Aim/Condition' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "aims = [k for k, v in question_adico_mapping.items() if 'Aim' in str(v) or 'Aim/Condition' in str(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now we make a random selection of questions with assigned ADICO components but later we can provide the model with a predetermined selection\n",
    "selected_attributes = random.sample(attributes, 3)\n",
    "selected_conditions = random.sample(conditions, 3)\n",
    "selected_aims = random.sample(aims, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Employment status\n",
      "Classification: Attribute/Condition\n",
      "Text: Employer type\n",
      "Classification: Attribute/Condition\n",
      "Text: Employment status\n",
      "Classification: Attribute/Condition\n"
     ]
    }
   ],
   "source": [
    "sampleinput = selected_attributes\n",
    "response = co.classify(\n",
    "  inputs=sampleinput,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "for classification in response.classifications:\n",
    "    print(\"Text:\", classification.input)\n",
    "    print(\"Classification:\", classification.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questiontext</th>\n",
       "      <th>responseoptions</th>\n",
       "      <th>question_answers_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>Title of dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title of dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essround</td>\n",
       "      <td>ESS round</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESS round</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edition</td>\n",
       "      <td>Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proddate</td>\n",
       "      <td>Production date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Production date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idno</td>\n",
       "      <td>Respondent's identification number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respondent's identification number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>mode</td>\n",
       "      <td>Mode of data collection</td>\n",
       "      <td>1: Interview, Face to face (CAPI); 2: Intervie...</td>\n",
       "      <td>Mode of data collection1: Interview, Face to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>domain</td>\n",
       "      <td>Sampling domain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sampling domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>prob</td>\n",
       "      <td>Sampling probability</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sampling probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>stratum</td>\n",
       "      <td>Sampling stratum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sampling stratum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>psu</td>\n",
       "      <td>Primary sampling unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary sampling unit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                        questiontext  \\\n",
       "0        name                    Title of dataset   \n",
       "1    essround                           ESS round   \n",
       "2     edition                             Edition   \n",
       "3    proddate                     Production date   \n",
       "4        idno  Respondent's identification number   \n",
       "..        ...                                 ...   \n",
       "613      mode             Mode of data collection   \n",
       "614    domain                     Sampling domain   \n",
       "615      prob                Sampling probability   \n",
       "616   stratum                    Sampling stratum   \n",
       "617       psu               Primary sampling unit   \n",
       "\n",
       "                                       responseoptions  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "613  1: Interview, Face to face (CAPI); 2: Intervie...   \n",
       "614                                                NaN   \n",
       "615                                                NaN   \n",
       "616                                                NaN   \n",
       "617                                                NaN   \n",
       "\n",
       "                             question_answers_combined  \n",
       "0                                     Title of dataset  \n",
       "1                                            ESS round  \n",
       "2                                              Edition  \n",
       "3                                      Production date  \n",
       "4                   Respondent's identification number  \n",
       "..                                                 ...  \n",
       "613  Mode of data collection1: Interview, Face to f...  \n",
       "614                                    Sampling domain  \n",
       "615                               Sampling probability  \n",
       "616                                   Sampling stratum  \n",
       "617                              Primary sampling unit  \n",
       "\n",
       "[618 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESSQuestionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Country of birth, father\n",
      "Classification: Attribute\n",
      "Text: Doing last 7 days: no answer\n",
      "Classification: Condition\n",
      "Text: Number of employees respondent has/had\n",
      "Classification: Condition\n",
      "Text: Travel time to child aged 12 or over, in minutes\n",
      "Classification: Condition\n",
      "Text: Control paid work last 7 days\n",
      "Classification: Condition\n"
     ]
    }
   ],
   "source": [
    "#Try for ESS Questions\n",
    "ESSQuestionData = pd.read_csv('ESSQuestionData.csv')\n",
    "ESS_Sample = list(ESSQuestionData['questiontext'].sample(5))\n",
    "\n",
    "response = co.classify(\n",
    "  inputs=ESS_Sample,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "for classification in response.classifications:\n",
    "    print(\"Text:\", classification.input)\n",
    "    print(\"Classification:\", classification.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the prompt\n",
    "prompt = \"Generate an Institutional shared strategy statement using all of the following sets of questions and answers containing Aims and Conditions:\\n\\n\"\n",
    "prompt += \"Aims:\\n\" + \"\\n\".join(selected_aims) + \"\\n\\n\"\n",
    "prompt += \"Conditions:\\n\" + \"\\n\".join(selected_conditions) + \"\\n\\n\"\n",
    "\n",
    "#Explain to the GPT what their role is:\n",
    "systemMessage = \"You are a helpful assistant that converts questions and answers from surveys into Institutional Behaviour Statements. You always output a list of statements that follow the following JSON structure: \\n\\n\"\n",
    "systemMessage += '{\"statements\":[\"Attribute\":\"Households in the Netherlands\", \"Aim\":\"do {Aim}\", \"Condition\":\"if {Condition(s)}]\"”\"\\n\\n\"'\n",
    "systemMessage += \"Your output will be read using the following: converted_questions = json.loads(response.choices[0].message.content) and converted_questions = pd.DataFrame(converted_questions_json['statements']).\"\n",
    "\n",
    "#Give them some context information:\n",
    "contentMessage = \"An institutional statement refers to a structured representation of institutions using specific elements such as Attribute, Deontic, Aim, Condition, and Or Else (ADICO). These statements are used to define and understand the impacts, actions, and conditions associated with institutional rules, norms, and shared strategies within social systems.\\n\\n\" \n",
    "contentMessage += \"Attribute: Who or what the impacts of the institution apply to, e.g. “Households in Indonesia” or “police officers”.\\n\\n\" \n",
    "contentMessage += \"Aim: The definition of the impact that is applied or the action performed, e.g. “reinforce their foundations bi-yearly” or “close the door”.\\n\\n\"\n",
    "contentMessage += \"Condition: the conditions that need to be satisfied in order for the aim to occur, e.g. “if they live with more than four people” or “if the alarm goes off”\\n\\n\"\n",
    "contentMessage += \"Combining all these elements produces the following Institutional shared strategy: “Police officers (Attribute) lock the doors of their vehicle (Aim) if they leave the vehicle (Condition)”'\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='```json\\n{\\n  \"statements\": [\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"do regularly read information about flooding and other hazards from the general media\",\\n      \"Condition\": \"if they believe that implementing non-structural measures, such as installing a refuge zone or an opening in the roof, would be affordable considering their income and expenses\"\\n    },\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"are more likely to consider implementing non-structural measures such as installing a refuge zone or an opening in the roof in the future\",\\n      \"Condition\": \"if they perceive the damage to their house from the 2020 flood as severe\"\\n    },\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"are willing to purchase sandbags or other water barriers as a non-structural measure\",\\n      \"Condition\": \"if they believe that this measure is affordable considering their income and other expenses\"\\n    }\\n  ]\\n}\\n```' generation_id='f9fb86ec-fd70-4a37-b148-58e72e9d0aa7' citations=None documents=None is_search_required=None search_queries=None search_results=None finish_reason='COMPLETE' tool_calls=None chat_history=[ChatMessage(role='USER', message='Generate an Institutional shared strategy statement using all of the following sets of questions and answers containing Aims and Conditions:\\n\\nAims:\\nHow frequently do you read information about flooding and other hazards?From the general media\\nPlease indicate if you have already implemented any of these nonstructural measures or if you intend to do so in the futureInstalling a refuge zone, or an opening in the roof of your home or apartment\\nPlease indicate if you have already implemented any of these nonstructural measures or if you intend to do so in the future\\n\\nConditions:\\nWhen you think in terms of your income and your other expenses, do you believe that implementing or paying someone to implement this nonstructural measure would be cheap or expensive?\\nWhen you think in terms of your income and your other expenses, do you believe that implementing or paying someone to implement this nonstructural measure would be cheap or expensive?Purchasing sandbags, or other water barriers\\nYou said you were affected by the 2020 Jakarta Flood. How severe was the damage to your house after the floods?\\n\\n'), ChatMessage(role='CHATBOT', message='```json\\n{\\n  \"statements\": [\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"do regularly read information about flooding and other hazards from the general media\",\\n      \"Condition\": \"if they believe that implementing non-structural measures, such as installing a refuge zone or an opening in the roof, would be affordable considering their income and expenses\"\\n    },\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"are more likely to consider implementing non-structural measures such as installing a refuge zone or an opening in the roof in the future\",\\n      \"Condition\": \"if they perceive the damage to their house from the 2020 flood as severe\"\\n    },\\n    {\\n      \"Attribute\": \"Households affected by the 2020 Jakarta Flood\",\\n      \"Aim\": \"are willing to purchase sandbags or other water barriers as a non-structural measure\",\\n      \"Condition\": \"if they believe that this measure is affordable considering their income and other expenses\"\\n    }\\n  ]\\n}\\n```')] meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=328, output_tokens=234, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=336, output_tokens=234), warnings=None) response_id='4fd4ffae-e148-41cc-a7a2-c0a03b536202'\n"
     ]
    }
   ],
   "source": [
    "response = co.chat(\n",
    "  preamble = systemMessage,\n",
    "  message=prompt,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Aim</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>do regularly read information about flooding a...</td>\n",
       "      <td>if they believe that implementing non-structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>are more likely to consider implementing non-s...</td>\n",
       "      <td>if they perceive the damage to their house fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Households affected by the 2020 Jakarta Flood</td>\n",
       "      <td>are willing to purchase sandbags or other wate...</td>\n",
       "      <td>if they believe that this measure is affordabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Attribute  \\\n",
       "0  Households affected by the 2020 Jakarta Flood   \n",
       "1  Households affected by the 2020 Jakarta Flood   \n",
       "2  Households affected by the 2020 Jakarta Flood   \n",
       "\n",
       "                                                 Aim  \\\n",
       "0  do regularly read information about flooding a...   \n",
       "1  are more likely to consider implementing non-s...   \n",
       "2  are willing to purchase sandbags or other wate...   \n",
       "\n",
       "                                           Condition  \n",
       "0  if they believe that implementing non-structur...  \n",
       "1  if they perceive the damage to their house fro...  \n",
       "2  if they believe that this measure is affordabl...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse JSON\n",
    "converted_questions_json = json.loads(response.text.replace('```json\\n', '').replace('```', ''))\n",
    "\n",
    "# Convert JSON to dataframe\n",
    "converted_questions = pd.DataFrame(converted_questions_json[\"statements\"])\n",
    "\n",
    "# Display dataframe\n",
    "converted_questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
