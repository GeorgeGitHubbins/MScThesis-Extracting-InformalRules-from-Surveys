{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to read ES Survey Data\n",
    "\n",
    "Number of participants by region and language used.\n",
    "The type of sample method used in the survey (simple, complex, etc.).\n",
    "What is the survey representative of when you use the sample weights and when you donâ€™t use the sample weights. This could be country, household, or individual.\n",
    "The questions you would like to use in the thesis together with some descriptive statistics (for this you can omit considering the sample design and weights):\n",
    "type of data: dichotomous; categorical (which categories); continuous (which range); open question (which language).\n",
    "Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>essround</th>\n",
       "      <th>edition</th>\n",
       "      <th>proddate</th>\n",
       "      <th>idno</th>\n",
       "      <th>cntry</th>\n",
       "      <th>dweight</th>\n",
       "      <th>pspwght</th>\n",
       "      <th>pweight</th>\n",
       "      <th>anweight</th>\n",
       "      <th>...</th>\n",
       "      <th>vinwe</th>\n",
       "      <th>inwde</th>\n",
       "      <th>jinws</th>\n",
       "      <th>jinwe</th>\n",
       "      <th>inwtm</th>\n",
       "      <th>mode</th>\n",
       "      <th>domain</th>\n",
       "      <th>prob</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10038</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.882220</td>\n",
       "      <td>0.972276</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.698167</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>188</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10053</td>\n",
       "      <td>BE</td>\n",
       "      <td>1.047643</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.638107</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-08 11:07:00</td>\n",
       "      <td>2022-04-08 11:10:00</td>\n",
       "      <td>2022-04-08 11:07:00</td>\n",
       "      <td>2022-04-08 11:10:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>194</td>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10055</td>\n",
       "      <td>BE</td>\n",
       "      <td>1.087741</td>\n",
       "      <td>0.722811</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.519033</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-20 11:08:00</td>\n",
       "      <td>2022-05-20 11:10:00</td>\n",
       "      <td>2022-05-20 11:08:00</td>\n",
       "      <td>2022-05-20 11:10:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>198</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10062</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>1.005565</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.722072</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-22 13:58:00</td>\n",
       "      <td>2022-05-22 13:59:00</td>\n",
       "      <td>2022-05-22 13:58:00</td>\n",
       "      <td>2022-05-22 13:59:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>150</td>\n",
       "      <td>2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10064</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>0.638705</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.458639</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-18 11:44:00</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>2022-05-18 11:44:00</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>149</td>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37606</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27808</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.339385</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-06-08 14:28:34</td>\n",
       "      <td>2021-06-08 14:30:41</td>\n",
       "      <td>2021-06-08 14:29:01</td>\n",
       "      <td>2021-06-08 14:31:44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>2610</td>\n",
       "      <td>27206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37607</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27826</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.297974</td>\n",
       "      <td>0.196093</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.063495</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-08-02 10:33:27</td>\n",
       "      <td>2021-08-02 10:36:27</td>\n",
       "      <td>2021-08-02 10:35:22</td>\n",
       "      <td>2021-08-02 10:37:34</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>2610</td>\n",
       "      <td>27217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37608</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27834</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.965931</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.277497</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-06-26 20:52:15</td>\n",
       "      <td>2021-06-26 20:53:05</td>\n",
       "      <td>2021-06-26 20:52:27</td>\n",
       "      <td>2021-06-26 20:54:32</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>2631</td>\n",
       "      <td>27134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37609</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27846</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.854279</td>\n",
       "      <td>0.624287</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.202144</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-21 14:14:41</td>\n",
       "      <td>2021-07-21 14:17:31</td>\n",
       "      <td>2021-07-21 14:16:38</td>\n",
       "      <td>2021-07-21 14:18:38</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>2638</td>\n",
       "      <td>27183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37610</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27858</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.702292</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.188442</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-11 10:48:52</td>\n",
       "      <td>2021-07-11 10:52:58</td>\n",
       "      <td>2021-07-11 10:52:10</td>\n",
       "      <td>2021-07-11 10:54:10</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>2620</td>\n",
       "      <td>27002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37611 rows Ã— 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  essround  edition    proddate   idno cntry   dweight  \\\n",
       "0      ESS10e03_2        10      3.2  02.11.2023  10038    BE  0.882220   \n",
       "1      ESS10e03_2        10      3.2  02.11.2023  10053    BE  1.047643   \n",
       "2      ESS10e03_2        10      3.2  02.11.2023  10055    BE  1.087741   \n",
       "3      ESS10e03_2        10      3.2  02.11.2023  10062    BE  0.909910   \n",
       "4      ESS10e03_2        10      3.2  02.11.2023  10064    BE  0.918949   \n",
       "...           ...       ...      ...         ...    ...   ...       ...   \n",
       "37606  ESS10e03_2        10      3.2  02.11.2023  27808    SK  0.515714   \n",
       "37607  ESS10e03_2        10      3.2  02.11.2023  27826    SK  0.297974   \n",
       "37608  ESS10e03_2        10      3.2  02.11.2023  27834    SK  0.965931   \n",
       "37609  ESS10e03_2        10      3.2  02.11.2023  27846    SK  0.854279   \n",
       "37610  ESS10e03_2        10      3.2  02.11.2023  27858    SK  0.702292   \n",
       "\n",
       "        pspwght   pweight  anweight  ...                vinwe  \\\n",
       "0      0.972276  0.718075  0.698167  ...  2022-09-01 17:47:00   \n",
       "1      0.888635  0.718075  0.638107  ...  2022-04-08 11:07:00   \n",
       "2      0.722811  0.718075  0.519033  ...  2022-05-20 11:08:00   \n",
       "3      1.005565  0.718075  0.722072  ...  2022-05-22 13:58:00   \n",
       "4      0.638705  0.718075  0.458639  ...  2022-05-18 11:44:00   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "37606  0.339385  0.323800  0.109893  ...  2021-06-08 14:28:34   \n",
       "37607  0.196093  0.323800  0.063495  ...  2021-08-02 10:33:27   \n",
       "37608  0.857000  0.323800  0.277497  ...  2021-06-26 20:52:15   \n",
       "37609  0.624287  0.323800  0.202144  ...  2021-07-21 14:14:41   \n",
       "37610  0.581970  0.323800  0.188442  ...  2021-07-11 10:48:52   \n",
       "\n",
       "                     inwde                jinws                jinwe  inwtm  \\\n",
       "0      2022-09-01 17:47:00  2022-09-01 17:47:00  2022-09-01 17:47:00   36.0   \n",
       "1      2022-04-08 11:10:00  2022-04-08 11:07:00  2022-04-08 11:10:00   54.0   \n",
       "2      2022-05-20 11:10:00  2022-05-20 11:08:00  2022-05-20 11:10:00   77.0   \n",
       "3      2022-05-22 13:59:00  2022-05-22 13:58:00  2022-05-22 13:59:00   55.0   \n",
       "4      2022-05-18 11:45:00  2022-05-18 11:44:00  2022-05-18 11:45:00   55.0   \n",
       "...                    ...                  ...                  ...    ...   \n",
       "37606  2021-06-08 14:30:41  2021-06-08 14:29:01  2021-06-08 14:31:44   70.0   \n",
       "37607  2021-08-02 10:36:27  2021-08-02 10:35:22  2021-08-02 10:37:34   45.0   \n",
       "37608  2021-06-26 20:53:05  2021-06-26 20:52:27  2021-06-26 20:54:32   33.0   \n",
       "37609  2021-07-21 14:17:31  2021-07-21 14:16:38  2021-07-21 14:18:38   43.0   \n",
       "37610  2021-07-11 10:52:58  2021-07-11 10:52:10  2021-07-11 10:54:10   49.0   \n",
       "\n",
       "       mode  domain      prob  stratum    psu  \n",
       "0         1     1.0  0.000397      188   2596  \n",
       "1         2     2.0  0.000334      194   2206  \n",
       "2         1     2.0  0.000322      198   2114  \n",
       "3         1     1.0  0.000385      150   2645  \n",
       "4         1     1.0  0.000381      149   2313  \n",
       "...     ...     ...       ...      ...    ...  \n",
       "37606     1     1.0  0.001522     2610  27206  \n",
       "37607     1     2.0  0.002635     2610  27217  \n",
       "37608     1     1.0  0.000813     2631  27134  \n",
       "37609     1     1.0  0.000919     2638  27183  \n",
       "37610     1     1.0  0.001118     2620  27002  \n",
       "\n",
       "[37611 rows x 618 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Responses  = pd.read_csv('ESS_files\\ESS10.csv', low_memory=False)\n",
    "# Clean the survey questions dataframe to make it more usable for mapping\n",
    "Survey_Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improveResponses(df):\n",
    "    # Iterate through the unique ids\n",
    "    for question_id in df['id'].unique():\n",
    "        # Select all rows with the same id\n",
    "        question_rows = df[df['id'] == question_id]\n",
    "\n",
    "        #Create a filtered list of question responses that are uninformative \n",
    "        filtered_min_responses = question_rows[question_rows['value'] == question_rows['response']]\n",
    "\n",
    "        # Check if there are multiple response options\n",
    "        if len(filtered_min_responses) >= 1:\n",
    "           \n",
    "            # Extract the unique values\n",
    "            unique_values = filtered_min_responses['value'].unique()\n",
    "            \n",
    "            min_value = str(int(unique_values.min()) - 1)\n",
    "            max_value = str(int(unique_values.max()) + 1)\n",
    "            \n",
    "            min_response = question_rows[question_rows['value'] == min_value]['response'].iloc[0]\n",
    "            max_response = question_rows[question_rows['value'] == max_value]['response'].iloc[0]\n",
    "            \n",
    "            # Iterate over each row and update the response for intermediate values\n",
    "            for idx, row in filtered_min_responses.iterrows():\n",
    "                if row['value'] not in [min_value, max_value]:# and row['value'] == row['response']:\n",
    "                    df.at[idx, 'response'] = f\"{row['value']}, where {min_value}: {min_response} and {max_value}: {max_response}\"\n",
    "    \n",
    "    return df['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the path to the HTML file\n",
    "html_file_path = 'ESS_files/ESS10 codebook.html'\n",
    "\n",
    "# Initialize a list to hold the rows of the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Read the HTML file\n",
    "with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "# Find all <h3> tags with an 'id' attribute (these contain the questions)\n",
    "question_tags = soup.find_all('h3', id=True)\n",
    "\n",
    "# Iterate over the question tags to extract the details\n",
    "for tag in question_tags:\n",
    "    idnumber = tag.get('id')  # Get the ID of the question\n",
    "    question = tag.find_next_sibling('div').text.strip()  # Get the question text\n",
    "    \n",
    "    # Find the next div that possibly contains the table\n",
    "    table_container = tag.find_next_sibling('div').find_next_sibling('div')\n",
    "    if table_container:\n",
    "        table = table_container.find('table')\n",
    "    else:\n",
    "        table = None\n",
    "\n",
    "    # If a table is found, extract options\n",
    "    if table:\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) == 2:  # Ensure exactly 2 cells are found (value and response)\n",
    "                value = cells[0].text.strip()\n",
    "                response = cells[1].text.strip()\n",
    "                # Append the extracted information as a row to the rows list\n",
    "                rows.append({\n",
    "                    'respid': idnumber+str(value), \n",
    "                    'id': idnumber,\n",
    "                    'question': question,\n",
    "                    'value': value,\n",
    "                    'response': response\n",
    "                })\n",
    "    else:\n",
    "        # If no table is found, append the question without response options\n",
    "        rows.append({\n",
    "            'respid': idnumber, \n",
    "            'id': idnumber,\n",
    "            'question': question,\n",
    "            'value': None,\n",
    "            'response': None\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the rows list\n",
    "Survey_Overview = pd.DataFrame(rows)\n",
    "\n",
    "# Apply the improveResponses function to the DataFrame\n",
    "Survey_Overview['response'] = improveResponses(Survey_Overview)\n",
    "\n",
    "Survey_Overview['question_answers_combined'] = Survey_Overview['question'] +\" - With response: \"+ Survey_Overview['response']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "Survey_Overview.to_csv(\"uncategorizedESS_Overview.csv\", index=False, sep=',')\n",
    "Survey_Overview\n",
    "Survey_Overview['ADICO_Category'] = \"\"\n",
    "Survey_Overview = Survey_Overview[Survey_Overview['value'] != None]\n",
    "Survey_Overview.set_index('respid', inplace=True)\n",
    "Survey_Overview = Survey_Overview.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>response</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>ADICO_Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imueclt8</th>\n",
       "      <td>imueclt</td>\n",
       "      <td>Country's cultural life undermined or enriched...</td>\n",
       "      <td>8</td>\n",
       "      <td>8, where 0: Cultural life undermined and 10: C...</td>\n",
       "      <td>Country's cultural life undermined or enriched...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hincsrca3</th>\n",
       "      <td>hincsrca</td>\n",
       "      <td>Main source of household income</td>\n",
       "      <td>3</td>\n",
       "      <td>Income from farming</td>\n",
       "      <td>Main source of household income - With respons...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvmdfr3</th>\n",
       "      <td>edlvmdfr</td>\n",
       "      <td>Mother's highest level of education, France</td>\n",
       "      <td>3</td>\n",
       "      <td>C - Certificat d'Ã©tudes primaires</td>\n",
       "      <td>Mother's highest level of education, France - ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isco081219</th>\n",
       "      <td>isco08</td>\n",
       "      <td>Occupation, ISCO08</td>\n",
       "      <td>1219</td>\n",
       "      <td>Business services and administration managers ...</td>\n",
       "      <td>Occupation, ISCO08 - With response: Business s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testic393</th>\n",
       "      <td>testic39</td>\n",
       "      <td>How likely, governments in enough countries ta...</td>\n",
       "      <td>3</td>\n",
       "      <td>Likely</td>\n",
       "      <td>How likely, governments in enough countries ta...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionFRL01</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>FRL01</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>Region - With response: Alpes-de-Haute-Provence</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isco082622</th>\n",
       "      <td>isco08</td>\n",
       "      <td>Occupation, ISCO08</td>\n",
       "      <td>2622</td>\n",
       "      <td>Librarians and related information professionals</td>\n",
       "      <td>Occupation, ISCO08 - With response: Librarians...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDEA5C</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DEA5C</td>\n",
       "      <td>Unna</td>\n",
       "      <td>Region - With response: Unna</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvpdch7777</th>\n",
       "      <td>edlvpdch</td>\n",
       "      <td>Partner's highest level of education, Switzerland</td>\n",
       "      <td>7777</td>\n",
       "      <td>Refusal*</td>\n",
       "      <td>Partner's highest level of education, Switzerl...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDE211</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DE211</td>\n",
       "      <td>Ingolstadt, Kreisfreie Stadt</td>\n",
       "      <td>Region - With response: Ingolstadt, Kreisfreie...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                           question  \\\n",
       "respid                                                                      \n",
       "imueclt8       imueclt  Country's cultural life undermined or enriched...   \n",
       "hincsrca3     hincsrca                    Main source of household income   \n",
       "edlvmdfr3     edlvmdfr        Mother's highest level of education, France   \n",
       "isco081219      isco08                                 Occupation, ISCO08   \n",
       "testic393     testic39  How likely, governments in enough countries ta...   \n",
       "regionFRL01     region                                             Region   \n",
       "isco082622      isco08                                 Occupation, ISCO08   \n",
       "regionDEA5C     region                                             Region   \n",
       "edlvpdch7777  edlvpdch  Partner's highest level of education, Switzerland   \n",
       "regionDE211     region                                             Region   \n",
       "\n",
       "              value                                           response  \\\n",
       "respid                                                                   \n",
       "imueclt8          8  8, where 0: Cultural life undermined and 10: C...   \n",
       "hincsrca3         3                                Income from farming   \n",
       "edlvmdfr3         3                  C - Certificat d'Ã©tudes primaires   \n",
       "isco081219     1219  Business services and administration managers ...   \n",
       "testic393         3                                             Likely   \n",
       "regionFRL01   FRL01                            Alpes-de-Haute-Provence   \n",
       "isco082622     2622   Librarians and related information professionals   \n",
       "regionDEA5C   DEA5C                                               Unna   \n",
       "edlvpdch7777   7777                                           Refusal*   \n",
       "regionDE211   DE211                       Ingolstadt, Kreisfreie Stadt   \n",
       "\n",
       "                                      question_answers_combined ADICO_Category  \n",
       "respid                                                                          \n",
       "imueclt8      Country's cultural life undermined or enriched...                 \n",
       "hincsrca3     Main source of household income - With respons...                 \n",
       "edlvmdfr3     Mother's highest level of education, France - ...                 \n",
       "isco081219    Occupation, ISCO08 - With response: Business s...                 \n",
       "testic393     How likely, governments in enough countries ta...                 \n",
       "regionFRL01     Region - With response: Alpes-de-Haute-Provence                 \n",
       "isco082622    Occupation, ISCO08 - With response: Librarians...                 \n",
       "regionDEA5C                        Region - With response: Unna                 \n",
       "edlvpdch7777  Partner's highest level of education, Switzerl...                 \n",
       "regionDE211   Region - With response: Ingolstadt, Kreisfreie...                 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Overview.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADICO Categorization of Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from groq import Groq\n",
    "# Now you can import the config module\n",
    "from config import groqkey, OPENAI_Key\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "groq = Groq(api_key=groqkey)\n",
    "\n",
    "import openai\n",
    "\n",
    "# Make sure to set your OpenAI API key\n",
    "openai.api_key = OPENAI_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the categorized survey questions in JSON format:\n",
      "\n",
      "[\n",
      "  {\"anctry182010\": {\"category\": \"Condition\"}},\n",
      "  {\"edlvesi11\": {\"category\": \"Condition\"}},\n",
      "  {\"cntbrthdNU\": {\"category\": \"Condition\"}}\n",
      "]\n",
      "\n",
      "Let me know if you have any further questions or if there's anything else I can help you with!\n"
     ]
    }
   ],
   "source": [
    "models = [\"gemma-7b-it\", \"llama3-8b-8192\", \"mixtral-8x7b-32768\", \"llama3-70b-8192\"]\n",
    "llm = ChatGroq(temperature=0, model=models[1], api_key=groqkey)\n",
    "\n",
    "\"Attribute: Only questions that directly ask for the responder's age, gender, location, or education. If it is not one of those it is a Condition.\\n None\"\n",
    "\n",
    "def categorize_ADICO(request):\n",
    "    \n",
    "    system = \"\"\"You are a helpful assistant that categorizes survey questions and presents them in JSON format.\n",
    "    The data you will receive is a json with the following structure:\n",
    "    ['id of the question':['question':'description of the question','response':'description of a potential response']]\n",
    "    \n",
    "    Possible categories are: \n",
    "    Aim: Question to identify if responder has performed an action,\n",
    "    Condition: Question on factors might impact the responder's behavior,\n",
    "    None: none of the above\n",
    "    \n",
    "    Format of your output:\n",
    "    ['id of the question':['category':'your assigned catgory'],]\n",
    "    \"\"\"\n",
    "\n",
    "    human = \"{text}\"\n",
    "    prompt  = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"text\": request})\n",
    "    return response.content\n",
    "\n",
    "filled_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "while len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"]) > 0:\n",
    "    set_to_categorize = Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"][['question', 'response']].sample(min(100, len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])))\n",
    "    set_to_categorizejson = set_to_categorize.to_json(orient='index', index=True)\n",
    "\n",
    "    response = categorize_ADICO(set_to_categorizejson)\n",
    "    \n",
    "    if \"error\" in response or \"Error\" in response: print(response) \n",
    "\n",
    "    try:\n",
    "        # Parse the JSON string into a Python dictionary\n",
    "        data_dict = json.loads(response)\n",
    "    except:\n",
    "        try:\n",
    "            # Parse the JSON string into a Python dictionary\n",
    "            data_dict = json.loads(\"[\" + response.split('[')[1].rsplit(']', 1)[0] + '}]')   \n",
    "        except:\n",
    "            data_dict = json.loads('[{' + '}'.join('{'.join(response.split('{')[1:]).split('}')[:-1]) + '}]')\n",
    "            \n",
    "    # Flatten the list of dictionaries into a single dictionary\n",
    "    try: flattened_data = {k: v['category'] for d in data_dict for k, v in d.items()}\n",
    "    except: flattened_data = {k: v for d in data_dict for k, v in d.items()}\n",
    "    # Convert the dictionary into a DataFrame\n",
    "    IG_component_df = pd.DataFrame(list(flattened_data.items()), columns=['respid', 'ADICO_Category']).set_index('respid', drop=True)\n",
    "    \n",
    "    originalCats = len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])\n",
    "   \n",
    "    # Update Survey_Overview with values from IG_component_df\n",
    "    Survey_Overview.update(IG_component_df)\n",
    "    \n",
    "    newCats = len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])\n",
    "\n",
    "\n",
    "    # Fill any empty Survey_Overview['ADICO_Category'] values if a row with the same Survey_Overview['id'] has a value\n",
    "    ids_with_category = Survey_Overview.loc[Survey_Overview['ADICO_Category'] != \"\", 'id'].unique()\n",
    "    \n",
    "    ids_with_category = [id for id in ids_with_category if id not in filled_ids]    \n",
    "    \n",
    "    for _id in ids_with_category:\n",
    "        categorizations_in_id = Survey_Overview.loc[Survey_Overview['id'] == _id, 'ADICO_Category'].dropna().unique()\n",
    "        if len(categorizations_in_id) > 2: print(Survey_Overview[Survey_Overview['id'] == _id])\n",
    "        Survey_Overview.loc[(Survey_Overview['id'] == _id) & (Survey_Overview['ADICO_Category'] == \"\"), 'ADICO_Category'] = Survey_Overview.loc[Survey_Overview['id'] == _id, 'ADICO_Category'].dropna().iloc[0]\n",
    "        filled_ids.append(_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>response</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>ADICO_Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mbrncntcEC</th>\n",
       "      <td>mbrncntc</td>\n",
       "      <td>Country of birth, mother</td>\n",
       "      <td>EC</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Country of birth, mother - With response: Ecuador</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbrncntcCF</th>\n",
       "      <td>fbrncntc</td>\n",
       "      <td>Country of birth, father</td>\n",
       "      <td>CF</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>Country of birth, father - With response: Cent...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDE259</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DE259</td>\n",
       "      <td>NÃ¼rnberger Land</td>\n",
       "      <td>Region - With response: NÃ¼rnberger Land</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvebe16</th>\n",
       "      <td>edlvebe</td>\n",
       "      <td>Highest level of education, Belgium</td>\n",
       "      <td>16</td>\n",
       "      <td>Universitair diploma van licentiaat of master;...</td>\n",
       "      <td>Highest level of education, Belgium - With res...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isco088150</th>\n",
       "      <td>isco08</td>\n",
       "      <td>Occupation, ISCO08</td>\n",
       "      <td>8150</td>\n",
       "      <td>Textile, fur and leather products machine oper...</td>\n",
       "      <td>Occupation, ISCO08 - With response: Textile, f...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDE128</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DE128</td>\n",
       "      <td>Rhein-Neckar-Kreis</td>\n",
       "      <td>Region - With response: Rhein-Neckar-Kreis</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom1SCO</th>\n",
       "      <td>lnghom1</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>SCO</td>\n",
       "      <td>Scots</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rshipa24</th>\n",
       "      <td>rshipa2</td>\n",
       "      <td>Second person in household: relationship to re...</td>\n",
       "      <td>4</td>\n",
       "      <td>Brother/sister/step/adopted/foster</td>\n",
       "      <td>Second person in household: relationship to re...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19spwrk3</th>\n",
       "      <td>c19spwrk</td>\n",
       "      <td>Speak with people you work with in person, how...</td>\n",
       "      <td>3</td>\n",
       "      <td>About the same</td>\n",
       "      <td>Speak with people you work with in person, how...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionES708</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>ES708</td>\n",
       "      <td>Lanzarote</td>\n",
       "      <td>Region - With response: Lanzarote</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           question  \\\n",
       "respid                                                                     \n",
       "mbrncntcEC   mbrncntc                           Country of birth, mother   \n",
       "fbrncntcCF   fbrncntc                           Country of birth, father   \n",
       "regionDE259    region                                             Region   \n",
       "edlvebe16     edlvebe                Highest level of education, Belgium   \n",
       "isco088150     isco08                                 Occupation, ISCO08   \n",
       "regionDE128    region                                             Region   \n",
       "lnghom1SCO    lnghom1  Language most often spoken at home: first ment...   \n",
       "rshipa24      rshipa2  Second person in household: relationship to re...   \n",
       "c19spwrk3    c19spwrk  Speak with people you work with in person, how...   \n",
       "regionES708    region                                             Region   \n",
       "\n",
       "             value                                           response  \\\n",
       "respid                                                                  \n",
       "mbrncntcEC      EC                                            Ecuador   \n",
       "fbrncntcCF      CF                           Central African Republic   \n",
       "regionDE259  DE259                                    NÃ¼rnberger Land   \n",
       "edlvebe16       16  Universitair diploma van licentiaat of master;...   \n",
       "isco088150    8150  Textile, fur and leather products machine oper...   \n",
       "regionDE128  DE128                                 Rhein-Neckar-Kreis   \n",
       "lnghom1SCO     SCO                                              Scots   \n",
       "rshipa24         4                 Brother/sister/step/adopted/foster   \n",
       "c19spwrk3        3                                     About the same   \n",
       "regionES708  ES708                                          Lanzarote   \n",
       "\n",
       "                                     question_answers_combined ADICO_Category  \n",
       "respid                                                                         \n",
       "mbrncntcEC   Country of birth, mother - With response: Ecuador      Condition  \n",
       "fbrncntcCF   Country of birth, father - With response: Cent...           None  \n",
       "regionDE259            Region - With response: NÃ¼rnberger Land      Condition  \n",
       "edlvebe16    Highest level of education, Belgium - With res...      Condition  \n",
       "isco088150   Occupation, ISCO08 - With response: Textile, f...      Condition  \n",
       "regionDE128         Region - With response: Rhein-Neckar-Kreis           None  \n",
       "lnghom1SCO   Language most often spoken at home: first ment...      Condition  \n",
       "rshipa24     Second person in household: relationship to re...           None  \n",
       "c19spwrk3    Speak with people you work with in person, how...           None  \n",
       "regionES708                  Region - With response: Lanzarote      Condition  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "Survey_Overview_path = 'ESSQuestionData_withADICO.csv'  # Update this path accordingly\n",
    "Survey_Overview.to_csv(Survey_Overview_path, index=True)\n",
    "\n",
    "Survey_Overview.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected aim\n",
    "chosen_aim = 'prtvthnl'\n",
    "\n",
    "#Filter responses:\n",
    "adjusted_responses = Survey_Responses[pd.notnull(Survey_Responses[chosen_aim])]\n",
    "\n",
    "#Remove:\n",
    "# 66: Not applicable*; \n",
    "# 77: Refusal*; \n",
    "# 88: Don't know*; \n",
    "# 99: No answer*\n",
    "adjusted_responses = adjusted_responses[adjusted_responses[chosen_aim] < 60]\n",
    "\n",
    "# set all votes vor other parties to other \n",
    "adjusted_responses.loc[adjusted_responses[chosen_aim] != 15, chosen_aim] = 31\n",
    "\n",
    "# Drop columns that contain any NaN values\n",
    "adjusted_responses = adjusted_responses.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>essround</th>\n",
       "      <th>edition</th>\n",
       "      <th>proddate</th>\n",
       "      <th>idno</th>\n",
       "      <th>cntry</th>\n",
       "      <th>dweight</th>\n",
       "      <th>pspwght</th>\n",
       "      <th>pweight</th>\n",
       "      <th>anweight</th>\n",
       "      <th>...</th>\n",
       "      <th>iinwe</th>\n",
       "      <th>kinwe</th>\n",
       "      <th>vinwe</th>\n",
       "      <th>inwde</th>\n",
       "      <th>jinws</th>\n",
       "      <th>jinwe</th>\n",
       "      <th>mode</th>\n",
       "      <th>prob</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>50005</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.974540</td>\n",
       "      <td>1.385130</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.391131</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-11-17 20:06:37</td>\n",
       "      <td>2021-11-17 20:12:27</td>\n",
       "      <td>2021-11-17 20:12:43</td>\n",
       "      <td>2021-11-17 20:14:04</td>\n",
       "      <td>2021-11-17 20:13:26</td>\n",
       "      <td>2021-11-17 20:14:14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>2197</td>\n",
       "      <td>18643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>50025</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.882231</td>\n",
       "      <td>1.381304</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.387288</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-01-25 12:02:44</td>\n",
       "      <td>2022-01-25 12:09:44</td>\n",
       "      <td>2022-01-25 12:10:07</td>\n",
       "      <td>2022-01-25 12:19:58</td>\n",
       "      <td>2022-01-25 12:19:17</td>\n",
       "      <td>2022-01-25 12:20:21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2222</td>\n",
       "      <td>17892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>50059</td>\n",
       "      <td>NL</td>\n",
       "      <td>1.028011</td>\n",
       "      <td>0.888868</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>0.892719</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-01-20 16:44:10</td>\n",
       "      <td>2022-01-20 16:48:54</td>\n",
       "      <td>2022-01-20 16:49:01</td>\n",
       "      <td>2022-01-20 16:49:50</td>\n",
       "      <td>2022-01-20 16:49:19</td>\n",
       "      <td>2022-01-20 16:49:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>2215</td>\n",
       "      <td>18639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>50120</td>\n",
       "      <td>NL</td>\n",
       "      <td>1.122778</td>\n",
       "      <td>1.044269</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.048793</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-10-23 11:58:43</td>\n",
       "      <td>2021-10-23 12:05:34</td>\n",
       "      <td>2021-10-23 12:05:45</td>\n",
       "      <td>2021-10-23 12:07:32</td>\n",
       "      <td>2021-10-23 12:06:54</td>\n",
       "      <td>2021-10-23 12:07:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>2234</td>\n",
       "      <td>17457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30227</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>50169</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.962268</td>\n",
       "      <td>0.630477</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>0.633208</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-10-29 10:50:58</td>\n",
       "      <td>2021-10-29 10:56:27</td>\n",
       "      <td>2021-10-29 10:56:32</td>\n",
       "      <td>2021-10-29 10:57:16</td>\n",
       "      <td>2021-10-29 10:56:55</td>\n",
       "      <td>2021-10-29 10:57:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>2201</td>\n",
       "      <td>18446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31683</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>81902</td>\n",
       "      <td>NL</td>\n",
       "      <td>1.122778</td>\n",
       "      <td>1.044269</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.048793</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-11-02 15:14:02</td>\n",
       "      <td>2021-11-02 15:20:01</td>\n",
       "      <td>2021-11-02 15:20:11</td>\n",
       "      <td>2021-11-02 15:21:35</td>\n",
       "      <td>2021-11-02 15:20:41</td>\n",
       "      <td>2021-11-02 17:59:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>2234</td>\n",
       "      <td>18318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31684</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>81903</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.974540</td>\n",
       "      <td>1.151910</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.156901</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-02-08 21:14:23</td>\n",
       "      <td>2022-02-08 21:21:05</td>\n",
       "      <td>2022-02-08 21:21:14</td>\n",
       "      <td>2022-02-09 14:47:53</td>\n",
       "      <td>2022-02-08 21:21:40</td>\n",
       "      <td>2022-02-09 14:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>2197</td>\n",
       "      <td>17422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31685</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>81932</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.985498</td>\n",
       "      <td>1.052108</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.056666</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-03-31 12:29:18</td>\n",
       "      <td>2022-03-31 12:36:05</td>\n",
       "      <td>2022-03-31 12:36:14</td>\n",
       "      <td>2022-03-31 12:38:01</td>\n",
       "      <td>2022-03-31 12:36:53</td>\n",
       "      <td>2022-03-31 12:38:08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>2236</td>\n",
       "      <td>18090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31686</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>82012</td>\n",
       "      <td>NL</td>\n",
       "      <td>1.028011</td>\n",
       "      <td>0.888868</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>0.892719</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-03-23 19:05:40</td>\n",
       "      <td>2022-03-23 19:11:40</td>\n",
       "      <td>2022-03-23 19:11:53</td>\n",
       "      <td>2022-03-23 19:33:50</td>\n",
       "      <td>2022-03-23 19:33:24</td>\n",
       "      <td>2022-03-23 19:33:56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>2215</td>\n",
       "      <td>18092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31688</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>82054</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.966499</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>0.762413</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-03-19 15:15:54</td>\n",
       "      <td>2022-03-19 15:20:55</td>\n",
       "      <td>2022-03-19 15:21:02</td>\n",
       "      <td>2022-03-19 15:21:48</td>\n",
       "      <td>2022-03-19 15:21:21</td>\n",
       "      <td>2022-03-19 15:21:53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>2223</td>\n",
       "      <td>18269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows Ã— 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  essround  edition    proddate   idno cntry   dweight  \\\n",
       "30222  ESS10e03_2        10      3.2  02.11.2023  50005    NL  0.974540   \n",
       "30223  ESS10e03_2        10      3.2  02.11.2023  50025    NL  0.882231   \n",
       "30224  ESS10e03_2        10      3.2  02.11.2023  50059    NL  1.028011   \n",
       "30226  ESS10e03_2        10      3.2  02.11.2023  50120    NL  1.122778   \n",
       "30227  ESS10e03_2        10      3.2  02.11.2023  50169    NL  0.962268   \n",
       "...           ...       ...      ...         ...    ...   ...       ...   \n",
       "31683  ESS10e03_2        10      3.2  02.11.2023  81902    NL  1.122778   \n",
       "31684  ESS10e03_2        10      3.2  02.11.2023  81903    NL  0.974540   \n",
       "31685  ESS10e03_2        10      3.2  02.11.2023  81932    NL  0.985498   \n",
       "31686  ESS10e03_2        10      3.2  02.11.2023  82012    NL  1.028011   \n",
       "31688  ESS10e03_2        10      3.2  02.11.2023  82054    NL  0.966499   \n",
       "\n",
       "        pspwght   pweight  anweight  ...                iinwe  \\\n",
       "30222  1.385130  1.004332  1.391131  ...  2021-11-17 20:06:37   \n",
       "30223  1.381304  1.004332  1.387288  ...  2022-01-25 12:02:44   \n",
       "30224  0.888868  1.004332  0.892719  ...  2022-01-20 16:44:10   \n",
       "30226  1.044269  1.004332  1.048793  ...  2021-10-23 11:58:43   \n",
       "30227  0.630477  1.004332  0.633208  ...  2021-10-29 10:50:58   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "31683  1.044269  1.004332  1.048793  ...  2021-11-02 15:14:02   \n",
       "31684  1.151910  1.004332  1.156901  ...  2022-02-08 21:14:23   \n",
       "31685  1.052108  1.004332  1.056666  ...  2022-03-31 12:29:18   \n",
       "31686  0.888868  1.004332  0.892719  ...  2022-03-23 19:05:40   \n",
       "31688  0.759124  1.004332  0.762413  ...  2022-03-19 15:15:54   \n",
       "\n",
       "                     kinwe                vinwe                inwde  \\\n",
       "30222  2021-11-17 20:12:27  2021-11-17 20:12:43  2021-11-17 20:14:04   \n",
       "30223  2022-01-25 12:09:44  2022-01-25 12:10:07  2022-01-25 12:19:58   \n",
       "30224  2022-01-20 16:48:54  2022-01-20 16:49:01  2022-01-20 16:49:50   \n",
       "30226  2021-10-23 12:05:34  2021-10-23 12:05:45  2021-10-23 12:07:32   \n",
       "30227  2021-10-29 10:56:27  2021-10-29 10:56:32  2021-10-29 10:57:16   \n",
       "...                    ...                  ...                  ...   \n",
       "31683  2021-11-02 15:20:01  2021-11-02 15:20:11  2021-11-02 15:21:35   \n",
       "31684  2022-02-08 21:21:05  2022-02-08 21:21:14  2022-02-09 14:47:53   \n",
       "31685  2022-03-31 12:36:05  2022-03-31 12:36:14  2022-03-31 12:38:01   \n",
       "31686  2022-03-23 19:11:40  2022-03-23 19:11:53  2022-03-23 19:33:50   \n",
       "31688  2022-03-19 15:20:55  2022-03-19 15:21:02  2022-03-19 15:21:48   \n",
       "\n",
       "                     jinws                jinwe  mode      prob  stratum  \\\n",
       "30222  2021-11-17 20:13:26  2021-11-17 20:14:14     1  0.000291     2197   \n",
       "30223  2022-01-25 12:19:17  2022-01-25 12:20:21     1  0.000322     2222   \n",
       "30224  2022-01-20 16:49:19  2022-01-20 16:49:58     1  0.000276     2215   \n",
       "30226  2021-10-23 12:06:54  2021-10-23 12:07:41     1  0.000253     2234   \n",
       "30227  2021-10-29 10:56:55  2021-10-29 10:57:22     1  0.000295     2201   \n",
       "...                    ...                  ...   ...       ...      ...   \n",
       "31683  2021-11-02 15:20:41  2021-11-02 17:59:10     1  0.000253     2234   \n",
       "31684  2022-02-08 21:21:40  2022-02-09 14:48:00     1  0.000291     2197   \n",
       "31685  2022-03-31 12:36:53  2022-03-31 12:38:08     1  0.000288     2236   \n",
       "31686  2022-03-23 19:33:24  2022-03-23 19:33:56     1  0.000276     2215   \n",
       "31688  2022-03-19 15:21:21  2022-03-19 15:21:53     1  0.000294     2223   \n",
       "\n",
       "         psu  \n",
       "30222  18643  \n",
       "30223  17892  \n",
       "30224  18639  \n",
       "30226  17457  \n",
       "30227  18446  \n",
       "...      ...  \n",
       "31683  18318  \n",
       "31684  17422  \n",
       "31685  18090  \n",
       "31686  18092  \n",
       "31688  18269  \n",
       "\n",
       "[1189 rows x 436 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Question Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Survey_Overview_path = 'ESSQuestionData_withADICO.csv'  # Update this path accordingly\n",
    "\n",
    "Survey_Overview_ADICO = pd.read_csv(Survey_Overview_path)\n",
    "\n",
    "Survey_Overview_ADICO.set_index('respid', inplace=True)\n",
    "Survey_Overview_ADICO.dropna(inplace=True)\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "Attributes = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Attribute', na=False), ['id', 'question_answers_combined']]\n",
    "Conditions = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Condition', na=False), ['id', 'question_answers_combined']]\n",
    "Aims = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Aim', na=False), ['id', 'question_answers_combined']]\n",
    "\n",
    "chosen_aims = Aims['id'].drop_duplicates().sample(3) \n",
    "chosen_conditions = Conditions['id'].drop_duplicates().sample(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prtvthnl\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m colnames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m paralelsetdf\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 15\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[43mSurvey_Overview_ADICO\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSurvey_Overview_ADICO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m     colnames\u001b[38;5;241m.\u001b[39mappend(question)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(col)\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:2440\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2439\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;124;03mQuickly retrieve single value at passed index label.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;124;03mscalar value\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[1;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming chosen_aims, chosen_conditions, Survey_Responses, and Survey_Overview_ADICO are already defined.\n",
    "\n",
    "# Loop through each item in the list of chosen aims\n",
    "for aim in [chosen_aim]:\n",
    "    # Combine base conditions with efficacy and cost conditions for the current aim\n",
    "    conditions = adjusted_responses.columns\n",
    "    paralelsetdf = adjusted_responses[[aim] + list(conditions)].dropna(how=\"any\")\n",
    "    \n",
    "    # Update the Column names to the question \n",
    "    colnames = []\n",
    "    for col in paralelsetdf.columns:\n",
    "        question = Survey_Overview_ADICO[Survey_Overview_ADICO[\"id\"] == col][\"question\"].iat[0]\n",
    "        colnames.append(question)\n",
    "        print(col)\n",
    "        if col == aim: continue\n",
    "        # Update labels to provide the needed information\n",
    "        for val in paralelsetdf[col].unique():\n",
    "            \n",
    "            try: response = Survey_Overview[(Survey_Overview[\"id\"] == col) & (Survey_Overview[\"value\"] == str(val))]['response'].iat[0]\n",
    "            except: response = Survey_Overview[(Survey_Overview[\"id\"] == col) & (Survey_Overview[\"value\"] == str(int(float(val))))]['response'].iat[0]\n",
    "            paralelsetdf[col] = paralelsetdf[col].replace(val, response)\n",
    "\n",
    "    paralelsetdf.columns = colnames\n",
    "\n",
    "    # Create the parallel categories plot\n",
    "    fig = px.parallel_categories(\n",
    "        paralelsetdf,\n",
    "        dimensions=colnames,\n",
    "        labels={col: col for col in colnames}  # This ensures the labels are the column names\n",
    "    )\n",
    "    \n",
    "    # Update the layout of the figure with a title and font size\n",
    "    title = Survey_Overview[Survey_Overview['id'] == aim][\"question\"].iloc[0]\n",
    "    fig.update_layout(title_text=title)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m numerical_answers \u001b[38;5;241m=\u001b[39m numerical_answers\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aim \u001b[38;5;129;01min\u001b[39;00m chosen_aims:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m numerical_answers\u001b[38;5;241m.\u001b[39mcolumns: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     aimRow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Survey_Overview_ADICO\u001b[38;5;241m.\u001b[39mloc[aim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion_answers_combined\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(aimRow)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# { \n",
    "#     \"alg\": \" HS512\"\n",
    "#     \"typ\": \"JWT\"\n",
    "# }\n",
    "numerical_answers = Survey_Responses.iloc[:,10:-34]\n",
    "\n",
    "# Try converting each column to numeric and coerce errors to NaN\n",
    "for column in numerical_answers.columns:\n",
    "    numerical_answers[column] = pd.to_numeric(numerical_answers[column], errors='coerce')\n",
    "\n",
    "# Drop columns that contain any NaN values (i.e., non-convertible columns)\n",
    "numerical_answers = numerical_answers.dropna(axis=1, how='any')\n",
    "\n",
    "for aim in chosen_aims:\n",
    "    if aim['id'] not in numerical_answers.columns: continue\n",
    "    aimRow = str(Survey_Overview_ADICO.loc[aim['id']]['question_answers_combined'])\n",
    "    print(aimRow)\n",
    "    class_names = Survey_Overview_ADICO['responseoptions']\n",
    "    feat_names = numerical_answers.loc[:, ~numerical_answers.columns.isin([aim])].columns\n",
    "    feature_descs = [Survey_Overview_ADICO[Survey_Overview_ADICO.index == feature]['question_answers_combined'].values for feature in feat_names if feature in list(Survey_Overview_ADICO.index)]\n",
    "\n",
    "    X = numerical_answers.loc[:, ~numerical_answers.columns.isin([aim])].values\n",
    "    Y = numerical_answers.loc[:, aim].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 100)\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = 'entropy', random_state=100, max_depth=1, min_samples_leaf=20)\n",
    "    clf_entropy.fit(X_train,y_train)\n",
    "    # Visualize the decision tree\n",
    "    plt.figure(figsize=(25,5))\n",
    "    plot_tree(clf_entropy, filled=True, feature_names=feature_descs, class_names = [str(item) for item in Survey_Responses[aim].unique()])\n",
    "    plt.show()\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    print((\"Accuracy is\"),accuracy_score(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Responses.loc[:, 'prtclbhr'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
