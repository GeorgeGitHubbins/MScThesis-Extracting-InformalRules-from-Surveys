{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to read ES Survey Data\n",
    "\n",
    "Number of participants by region and language used.\n",
    "The type of sample method used in the survey (simple, complex, etc.).\n",
    "What is the survey representative of when you use the sample weights and when you don’t use the sample weights. This could be country, household, or individual.\n",
    "The questions you would like to use in the thesis together with some descriptive statistics (for this you can omit considering the sample design and weights):\n",
    "type of data: dichotomous; categorical (which categories); continuous (which range); open question (which language).\n",
    "Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>essround</th>\n",
       "      <th>edition</th>\n",
       "      <th>proddate</th>\n",
       "      <th>idno</th>\n",
       "      <th>cntry</th>\n",
       "      <th>dweight</th>\n",
       "      <th>pspwght</th>\n",
       "      <th>pweight</th>\n",
       "      <th>anweight</th>\n",
       "      <th>...</th>\n",
       "      <th>vinwe</th>\n",
       "      <th>inwde</th>\n",
       "      <th>jinws</th>\n",
       "      <th>jinwe</th>\n",
       "      <th>inwtm</th>\n",
       "      <th>mode</th>\n",
       "      <th>domain</th>\n",
       "      <th>prob</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10038</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.882220</td>\n",
       "      <td>0.972276</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.698167</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>2022-09-01 17:47:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>188</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10053</td>\n",
       "      <td>BE</td>\n",
       "      <td>1.047643</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.638107</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-08 11:07:00</td>\n",
       "      <td>2022-04-08 11:10:00</td>\n",
       "      <td>2022-04-08 11:07:00</td>\n",
       "      <td>2022-04-08 11:10:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>194</td>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10055</td>\n",
       "      <td>BE</td>\n",
       "      <td>1.087741</td>\n",
       "      <td>0.722811</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.519033</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-20 11:08:00</td>\n",
       "      <td>2022-05-20 11:10:00</td>\n",
       "      <td>2022-05-20 11:08:00</td>\n",
       "      <td>2022-05-20 11:10:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>198</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10062</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>1.005565</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.722072</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-22 13:58:00</td>\n",
       "      <td>2022-05-22 13:59:00</td>\n",
       "      <td>2022-05-22 13:58:00</td>\n",
       "      <td>2022-05-22 13:59:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>150</td>\n",
       "      <td>2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>10064</td>\n",
       "      <td>BE</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>0.638705</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.458639</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-18 11:44:00</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>2022-05-18 11:44:00</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>149</td>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37606</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27808</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.339385</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-06-08 14:28:34</td>\n",
       "      <td>2021-06-08 14:30:41</td>\n",
       "      <td>2021-06-08 14:29:01</td>\n",
       "      <td>2021-06-08 14:31:44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>2610</td>\n",
       "      <td>27206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37607</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27826</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.297974</td>\n",
       "      <td>0.196093</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.063495</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-08-02 10:33:27</td>\n",
       "      <td>2021-08-02 10:36:27</td>\n",
       "      <td>2021-08-02 10:35:22</td>\n",
       "      <td>2021-08-02 10:37:34</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>2610</td>\n",
       "      <td>27217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37608</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27834</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.965931</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.277497</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-06-26 20:52:15</td>\n",
       "      <td>2021-06-26 20:53:05</td>\n",
       "      <td>2021-06-26 20:52:27</td>\n",
       "      <td>2021-06-26 20:54:32</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>2631</td>\n",
       "      <td>27134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37609</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27846</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.854279</td>\n",
       "      <td>0.624287</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.202144</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-21 14:14:41</td>\n",
       "      <td>2021-07-21 14:17:31</td>\n",
       "      <td>2021-07-21 14:16:38</td>\n",
       "      <td>2021-07-21 14:18:38</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>2638</td>\n",
       "      <td>27183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37610</th>\n",
       "      <td>ESS10e03_2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>02.11.2023</td>\n",
       "      <td>27858</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.702292</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.188442</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-11 10:48:52</td>\n",
       "      <td>2021-07-11 10:52:58</td>\n",
       "      <td>2021-07-11 10:52:10</td>\n",
       "      <td>2021-07-11 10:54:10</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>2620</td>\n",
       "      <td>27002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37611 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  essround  edition    proddate   idno cntry   dweight  \\\n",
       "0      ESS10e03_2        10      3.2  02.11.2023  10038    BE  0.882220   \n",
       "1      ESS10e03_2        10      3.2  02.11.2023  10053    BE  1.047643   \n",
       "2      ESS10e03_2        10      3.2  02.11.2023  10055    BE  1.087741   \n",
       "3      ESS10e03_2        10      3.2  02.11.2023  10062    BE  0.909910   \n",
       "4      ESS10e03_2        10      3.2  02.11.2023  10064    BE  0.918949   \n",
       "...           ...       ...      ...         ...    ...   ...       ...   \n",
       "37606  ESS10e03_2        10      3.2  02.11.2023  27808    SK  0.515714   \n",
       "37607  ESS10e03_2        10      3.2  02.11.2023  27826    SK  0.297974   \n",
       "37608  ESS10e03_2        10      3.2  02.11.2023  27834    SK  0.965931   \n",
       "37609  ESS10e03_2        10      3.2  02.11.2023  27846    SK  0.854279   \n",
       "37610  ESS10e03_2        10      3.2  02.11.2023  27858    SK  0.702292   \n",
       "\n",
       "        pspwght   pweight  anweight  ...                vinwe  \\\n",
       "0      0.972276  0.718075  0.698167  ...  2022-09-01 17:47:00   \n",
       "1      0.888635  0.718075  0.638107  ...  2022-04-08 11:07:00   \n",
       "2      0.722811  0.718075  0.519033  ...  2022-05-20 11:08:00   \n",
       "3      1.005565  0.718075  0.722072  ...  2022-05-22 13:58:00   \n",
       "4      0.638705  0.718075  0.458639  ...  2022-05-18 11:44:00   \n",
       "...         ...       ...       ...  ...                  ...   \n",
       "37606  0.339385  0.323800  0.109893  ...  2021-06-08 14:28:34   \n",
       "37607  0.196093  0.323800  0.063495  ...  2021-08-02 10:33:27   \n",
       "37608  0.857000  0.323800  0.277497  ...  2021-06-26 20:52:15   \n",
       "37609  0.624287  0.323800  0.202144  ...  2021-07-21 14:14:41   \n",
       "37610  0.581970  0.323800  0.188442  ...  2021-07-11 10:48:52   \n",
       "\n",
       "                     inwde                jinws                jinwe  inwtm  \\\n",
       "0      2022-09-01 17:47:00  2022-09-01 17:47:00  2022-09-01 17:47:00   36.0   \n",
       "1      2022-04-08 11:10:00  2022-04-08 11:07:00  2022-04-08 11:10:00   54.0   \n",
       "2      2022-05-20 11:10:00  2022-05-20 11:08:00  2022-05-20 11:10:00   77.0   \n",
       "3      2022-05-22 13:59:00  2022-05-22 13:58:00  2022-05-22 13:59:00   55.0   \n",
       "4      2022-05-18 11:45:00  2022-05-18 11:44:00  2022-05-18 11:45:00   55.0   \n",
       "...                    ...                  ...                  ...    ...   \n",
       "37606  2021-06-08 14:30:41  2021-06-08 14:29:01  2021-06-08 14:31:44   70.0   \n",
       "37607  2021-08-02 10:36:27  2021-08-02 10:35:22  2021-08-02 10:37:34   45.0   \n",
       "37608  2021-06-26 20:53:05  2021-06-26 20:52:27  2021-06-26 20:54:32   33.0   \n",
       "37609  2021-07-21 14:17:31  2021-07-21 14:16:38  2021-07-21 14:18:38   43.0   \n",
       "37610  2021-07-11 10:52:58  2021-07-11 10:52:10  2021-07-11 10:54:10   49.0   \n",
       "\n",
       "       mode  domain      prob  stratum    psu  \n",
       "0         1     1.0  0.000397      188   2596  \n",
       "1         2     2.0  0.000334      194   2206  \n",
       "2         1     2.0  0.000322      198   2114  \n",
       "3         1     1.0  0.000385      150   2645  \n",
       "4         1     1.0  0.000381      149   2313  \n",
       "...     ...     ...       ...      ...    ...  \n",
       "37606     1     1.0  0.001522     2610  27206  \n",
       "37607     1     2.0  0.002635     2610  27217  \n",
       "37608     1     1.0  0.000813     2631  27134  \n",
       "37609     1     1.0  0.000919     2638  27183  \n",
       "37610     1     1.0  0.001118     2620  27002  \n",
       "\n",
       "[37611 rows x 618 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Responses  = pd.read_csv('ESS_files\\ESS10.csv', low_memory=False)\n",
    "# Clean the survey questions dataframe to make it more usable for mapping\n",
    "Survey_Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improveResponses(df):\n",
    "    # Iterate through the unique ids\n",
    "    for question_id in df['id'].unique():\n",
    "        # Select all rows with the same id\n",
    "        question_rows = df[df['id'] == question_id]\n",
    "\n",
    "        #Create a filtered list of question responses that are uninformative \n",
    "        filtered_min_responses = question_rows[question_rows['value'] == question_rows['response']]\n",
    "\n",
    "        # Check if there are multiple response options\n",
    "        if len(filtered_min_responses) >= 1:\n",
    "           \n",
    "            # Extract the unique values\n",
    "            unique_values = filtered_min_responses['value'].unique()\n",
    "            \n",
    "            min_value = str(int(unique_values.min()) - 1)\n",
    "            max_value = str(int(unique_values.max()) + 1)\n",
    "            \n",
    "            min_response = question_rows[question_rows['value'] == min_value]['response'].iloc[0]\n",
    "            max_response = question_rows[question_rows['value'] == max_value]['response'].iloc[0]\n",
    "            \n",
    "            # Iterate over each row and update the response for intermediate values\n",
    "            for idx, row in filtered_min_responses.iterrows():\n",
    "                if row['value'] not in [min_value, max_value]:# and row['value'] == row['response']:\n",
    "                    df.at[idx, 'response'] = f\"{row['value']}, where {min_value}: {min_response} and {max_value}: {max_response}\"\n",
    "    \n",
    "    return df['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the path to the HTML file\n",
    "html_file_path = 'ESS_files/ESS10 codebook.html'\n",
    "\n",
    "# Initialize a list to hold the rows of the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Read the HTML file\n",
    "with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "# Find all <h3> tags with an 'id' attribute (these contain the questions)\n",
    "question_tags = soup.find_all('h3', id=True)\n",
    "\n",
    "# Iterate over the question tags to extract the details\n",
    "for tag in question_tags:\n",
    "    idnumber = tag.get('id')  # Get the ID of the question\n",
    "    question = tag.find_next_sibling('div').text.strip()  # Get the question text\n",
    "    \n",
    "    # Find the next div that possibly contains the table\n",
    "    table_container = tag.find_next_sibling('div').find_next_sibling('div')\n",
    "    if table_container:\n",
    "        table = table_container.find('table')\n",
    "    else:\n",
    "        table = None\n",
    "\n",
    "    # If a table is found, extract options\n",
    "    if table:\n",
    "        for row in table.find_all('tr'):\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) == 2:  # Ensure exactly 2 cells are found (value and response)\n",
    "                value = cells[0].text.strip()\n",
    "                response = cells[1].text.strip()\n",
    "                # Append the extracted information as a row to the rows list\n",
    "                rows.append({\n",
    "                    'respid': idnumber+str(value), \n",
    "                    'id': idnumber,\n",
    "                    'question': question,\n",
    "                    'value': value,\n",
    "                    'response': response\n",
    "                })\n",
    "    else:\n",
    "        # If no table is found, append the question without response options\n",
    "        rows.append({\n",
    "            'respid': idnumber, \n",
    "            'id': idnumber,\n",
    "            'question': question,\n",
    "            'value': None,\n",
    "            'response': None\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the rows list\n",
    "Survey_Overview = pd.DataFrame(rows)\n",
    "\n",
    "# Apply the improveResponses function to the DataFrame\n",
    "Survey_Overview['response'] = improveResponses(Survey_Overview)\n",
    "\n",
    "Survey_Overview['question_answers_combined'] = Survey_Overview['question'] +\" - With response: \"+ Survey_Overview['response']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "Survey_Overview.to_csv(\"uncategorizedESS_Overview.csv\", index=False, sep=',')\n",
    "Survey_Overview\n",
    "Survey_Overview['ADICO_Category'] = \"\"\n",
    "Survey_Overview = Survey_Overview[Survey_Overview['value'] != None]\n",
    "Survey_Overview.set_index('respid', inplace=True)\n",
    "Survey_Overview = Survey_Overview.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>response</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>ADICO_Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accalaw10</th>\n",
       "      <td>accalaw</td>\n",
       "      <td>Acceptable for country to have a strong leader...</td>\n",
       "      <td>10</td>\n",
       "      <td>Completely acceptable</td>\n",
       "      <td>Acceptable for country to have a strong leader...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prtclesk1</th>\n",
       "      <td>prtclesk</td>\n",
       "      <td>Which party feel closer to, Slovakia</td>\n",
       "      <td>1</td>\n",
       "      <td>Obyčajní Ľudia a nezávislé osobnosti</td>\n",
       "      <td>Which party feel closer to, Slovakia - With re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom1ALG</th>\n",
       "      <td>lnghom1</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>ALG</td>\n",
       "      <td>Algonquian languages</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occm14b1</th>\n",
       "      <td>occm14b</td>\n",
       "      <td>Mother's occupation when respondent 14</td>\n",
       "      <td>1</td>\n",
       "      <td>Professional and technical occupations</td>\n",
       "      <td>Mother's occupation when respondent 14 - With ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvfdpt4</th>\n",
       "      <td>edlvfdpt</td>\n",
       "      <td>Father's highest level of education, Portugal</td>\n",
       "      <td>4</td>\n",
       "      <td>Cursos de educação e formação de tipo 1. Atrib...</td>\n",
       "      <td>Father's highest level of education, Portugal ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom1GRB</th>\n",
       "      <td>lnghom1</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>GRB</td>\n",
       "      <td>Grebo</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom2MAK</th>\n",
       "      <td>lnghom2</td>\n",
       "      <td>Language most often spoken at home: second men...</td>\n",
       "      <td>MAK</td>\n",
       "      <td>Makasar</td>\n",
       "      <td>Language most often spoken at home: second men...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom1XAL</th>\n",
       "      <td>lnghom1</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>XAL</td>\n",
       "      <td>Kalmyk, Oriat</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvebg14</th>\n",
       "      <td>edlvebg</td>\n",
       "      <td>Highest level of education, Bulgaria</td>\n",
       "      <td>14</td>\n",
       "      <td>Visshe - Doktor</td>\n",
       "      <td>Highest level of education, Bulgaria - With re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colprop99</th>\n",
       "      <td>colprop</td>\n",
       "      <td>Proportion of colleagues based at the same loc...</td>\n",
       "      <td>99</td>\n",
       "      <td>No answer*</td>\n",
       "      <td>Proportion of colleagues based at the same loc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question value  \\\n",
       "respid                                                                          \n",
       "accalaw10    accalaw  Acceptable for country to have a strong leader...    10   \n",
       "prtclesk1   prtclesk               Which party feel closer to, Slovakia     1   \n",
       "lnghom1ALG   lnghom1  Language most often spoken at home: first ment...   ALG   \n",
       "occm14b1     occm14b             Mother's occupation when respondent 14     1   \n",
       "edlvfdpt4   edlvfdpt      Father's highest level of education, Portugal     4   \n",
       "lnghom1GRB   lnghom1  Language most often spoken at home: first ment...   GRB   \n",
       "lnghom2MAK   lnghom2  Language most often spoken at home: second men...   MAK   \n",
       "lnghom1XAL   lnghom1  Language most often spoken at home: first ment...   XAL   \n",
       "edlvebg14    edlvebg               Highest level of education, Bulgaria    14   \n",
       "colprop99    colprop  Proportion of colleagues based at the same loc...    99   \n",
       "\n",
       "                                                     response  \\\n",
       "respid                                                          \n",
       "accalaw10                               Completely acceptable   \n",
       "prtclesk1                Obyčajní Ľudia a nezávislé osobnosti   \n",
       "lnghom1ALG                               Algonquian languages   \n",
       "occm14b1               Professional and technical occupations   \n",
       "edlvfdpt4   Cursos de educação e formação de tipo 1. Atrib...   \n",
       "lnghom1GRB                                              Grebo   \n",
       "lnghom2MAK                                            Makasar   \n",
       "lnghom1XAL                                      Kalmyk, Oriat   \n",
       "edlvebg14                                     Visshe - Doktor   \n",
       "colprop99                                          No answer*   \n",
       "\n",
       "                                    question_answers_combined ADICO_Category  \n",
       "respid                                                                        \n",
       "accalaw10   Acceptable for country to have a strong leader...                 \n",
       "prtclesk1   Which party feel closer to, Slovakia - With re...                 \n",
       "lnghom1ALG  Language most often spoken at home: first ment...                 \n",
       "occm14b1    Mother's occupation when respondent 14 - With ...                 \n",
       "edlvfdpt4   Father's highest level of education, Portugal ...                 \n",
       "lnghom1GRB  Language most often spoken at home: first ment...                 \n",
       "lnghom2MAK  Language most often spoken at home: second men...                 \n",
       "lnghom1XAL  Language most often spoken at home: first ment...                 \n",
       "edlvebg14   Highest level of education, Bulgaria - With re...                 \n",
       "colprop99   Proportion of colleagues based at the same loc...                 "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Overview.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADICO Categorization of Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from groq import Groq\n",
    "# Now you can import the config module\n",
    "from config import groqkey, OPENAI_Key\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "groq = Groq(api_key=groqkey)\n",
    "\n",
    "import openai\n",
    "\n",
    "# Make sure to set your OpenAI API key\n",
    "openai.api_key = OPENAI_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the categorized survey questions in JSON format:\n",
      "\n",
      "[\n",
      "  {\"anctry182010\": {\"category\": \"Condition\"}},\n",
      "  {\"edlvesi11\": {\"category\": \"Condition\"}},\n",
      "  {\"cntbrthdNU\": {\"category\": \"Condition\"}}\n",
      "]\n",
      "\n",
      "Let me know if you have any further questions or if there's anything else I can help you with!\n"
     ]
    }
   ],
   "source": [
    "models = [\"gemma-7b-it\", \"llama3-8b-8192\", \"mixtral-8x7b-32768\", \"llama3-70b-8192\"]\n",
    "llm = ChatGroq(temperature=0, model=models[1], api_key=groqkey)\n",
    "\n",
    "\"Attribute: Only questions that directly ask for the responder's age, gender, location, or education. If it is not one of those it is a Condition.\\n None\"\n",
    "\n",
    "def categorize_ADICO(request):\n",
    "    \n",
    "    system = \"\"\"You are a helpful assistant that categorizes survey questions and presents them in JSON format.\n",
    "    The data you will receive is a json with the following structure:\n",
    "    ['id of the question':['question':'description of the question','response':'description of a potential response']]\n",
    "    \n",
    "    Possible categories are: \n",
    "    Aim: Question to identify if responder has performed an action,\n",
    "    Condition: Question on factors might impact the responder's behavior,\n",
    "    None: none of the above\n",
    "    \n",
    "    Format of your output:\n",
    "    ['id of the question':['category':'your assigned catgory'],]\n",
    "    \"\"\"\n",
    "\n",
    "    human = \"{text}\"\n",
    "    prompt  = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"text\": request})\n",
    "    return response.content\n",
    "\n",
    "filled_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "while len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"]) > 0:\n",
    "    set_to_categorize = Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"][['question', 'response']].sample(min(100, len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])))\n",
    "    set_to_categorizejson = set_to_categorize.to_json(orient='index', index=True)\n",
    "\n",
    "    response = categorize_ADICO(set_to_categorizejson)\n",
    "    \n",
    "    if \"error\" in response or \"Error\" in response: print(response) \n",
    "\n",
    "    try:\n",
    "        # Parse the JSON string into a Python dictionary\n",
    "        data_dict = json.loads(response)\n",
    "    except:\n",
    "        try:\n",
    "            # Parse the JSON string into a Python dictionary\n",
    "            data_dict = json.loads(\"[\" + response.split('[')[1].rsplit(']', 1)[0] + '}]')   \n",
    "        except:\n",
    "            data_dict = json.loads('[{' + '}'.join('{'.join(response.split('{')[1:]).split('}')[:-1]) + '}]')\n",
    "            \n",
    "    # Flatten the list of dictionaries into a single dictionary\n",
    "    try: flattened_data = {k: v['category'] for d in data_dict for k, v in d.items()}\n",
    "    except: flattened_data = {k: v for d in data_dict for k, v in d.items()}\n",
    "    # Convert the dictionary into a DataFrame\n",
    "    IG_component_df = pd.DataFrame(list(flattened_data.items()), columns=['respid', 'ADICO_Category']).set_index('respid', drop=True)\n",
    "    \n",
    "    originalCats = len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])\n",
    "   \n",
    "    # Update Survey_Overview with values from IG_component_df\n",
    "    Survey_Overview.update(IG_component_df)\n",
    "    \n",
    "    newCats = len(Survey_Overview[Survey_Overview['ADICO_Category'] == \"\"])\n",
    "\n",
    "\n",
    "    # Fill any empty Survey_Overview['ADICO_Category'] values if a row with the same Survey_Overview['id'] has a value\n",
    "    ids_with_category = Survey_Overview.loc[Survey_Overview['ADICO_Category'] != \"\", 'id'].unique()\n",
    "    \n",
    "    ids_with_category = [id for id in ids_with_category if id not in filled_ids]    \n",
    "    \n",
    "    for _id in ids_with_category:\n",
    "        categorizations_in_id = Survey_Overview.loc[Survey_Overview['id'] == _id, 'ADICO_Category'].dropna().unique()\n",
    "        if len(categorizations_in_id) > 2: print(Survey_Overview[Survey_Overview['id'] == _id])\n",
    "        Survey_Overview.loc[(Survey_Overview['id'] == _id) & (Survey_Overview['ADICO_Category'] == \"\"), 'ADICO_Category'] = Survey_Overview.loc[Survey_Overview['id'] == _id, 'ADICO_Category'].dropna().iloc[0]\n",
    "        filled_ids.append(_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>response</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>ADICO_Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mbrncntcEC</th>\n",
       "      <td>mbrncntc</td>\n",
       "      <td>Country of birth, mother</td>\n",
       "      <td>EC</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Country of birth, mother - With response: Ecuador</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbrncntcCF</th>\n",
       "      <td>fbrncntc</td>\n",
       "      <td>Country of birth, father</td>\n",
       "      <td>CF</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>Country of birth, father - With response: Cent...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDE259</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DE259</td>\n",
       "      <td>Nürnberger Land</td>\n",
       "      <td>Region - With response: Nürnberger Land</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edlvebe16</th>\n",
       "      <td>edlvebe</td>\n",
       "      <td>Highest level of education, Belgium</td>\n",
       "      <td>16</td>\n",
       "      <td>Universitair diploma van licentiaat of master;...</td>\n",
       "      <td>Highest level of education, Belgium - With res...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isco088150</th>\n",
       "      <td>isco08</td>\n",
       "      <td>Occupation, ISCO08</td>\n",
       "      <td>8150</td>\n",
       "      <td>Textile, fur and leather products machine oper...</td>\n",
       "      <td>Occupation, ISCO08 - With response: Textile, f...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionDE128</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>DE128</td>\n",
       "      <td>Rhein-Neckar-Kreis</td>\n",
       "      <td>Region - With response: Rhein-Neckar-Kreis</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnghom1SCO</th>\n",
       "      <td>lnghom1</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>SCO</td>\n",
       "      <td>Scots</td>\n",
       "      <td>Language most often spoken at home: first ment...</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rshipa24</th>\n",
       "      <td>rshipa2</td>\n",
       "      <td>Second person in household: relationship to re...</td>\n",
       "      <td>4</td>\n",
       "      <td>Brother/sister/step/adopted/foster</td>\n",
       "      <td>Second person in household: relationship to re...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19spwrk3</th>\n",
       "      <td>c19spwrk</td>\n",
       "      <td>Speak with people you work with in person, how...</td>\n",
       "      <td>3</td>\n",
       "      <td>About the same</td>\n",
       "      <td>Speak with people you work with in person, how...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionES708</th>\n",
       "      <td>region</td>\n",
       "      <td>Region</td>\n",
       "      <td>ES708</td>\n",
       "      <td>Lanzarote</td>\n",
       "      <td>Region - With response: Lanzarote</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           question  \\\n",
       "respid                                                                     \n",
       "mbrncntcEC   mbrncntc                           Country of birth, mother   \n",
       "fbrncntcCF   fbrncntc                           Country of birth, father   \n",
       "regionDE259    region                                             Region   \n",
       "edlvebe16     edlvebe                Highest level of education, Belgium   \n",
       "isco088150     isco08                                 Occupation, ISCO08   \n",
       "regionDE128    region                                             Region   \n",
       "lnghom1SCO    lnghom1  Language most often spoken at home: first ment...   \n",
       "rshipa24      rshipa2  Second person in household: relationship to re...   \n",
       "c19spwrk3    c19spwrk  Speak with people you work with in person, how...   \n",
       "regionES708    region                                             Region   \n",
       "\n",
       "             value                                           response  \\\n",
       "respid                                                                  \n",
       "mbrncntcEC      EC                                            Ecuador   \n",
       "fbrncntcCF      CF                           Central African Republic   \n",
       "regionDE259  DE259                                    Nürnberger Land   \n",
       "edlvebe16       16  Universitair diploma van licentiaat of master;...   \n",
       "isco088150    8150  Textile, fur and leather products machine oper...   \n",
       "regionDE128  DE128                                 Rhein-Neckar-Kreis   \n",
       "lnghom1SCO     SCO                                              Scots   \n",
       "rshipa24         4                 Brother/sister/step/adopted/foster   \n",
       "c19spwrk3        3                                     About the same   \n",
       "regionES708  ES708                                          Lanzarote   \n",
       "\n",
       "                                     question_answers_combined ADICO_Category  \n",
       "respid                                                                         \n",
       "mbrncntcEC   Country of birth, mother - With response: Ecuador      Condition  \n",
       "fbrncntcCF   Country of birth, father - With response: Cent...           None  \n",
       "regionDE259            Region - With response: Nürnberger Land      Condition  \n",
       "edlvebe16    Highest level of education, Belgium - With res...      Condition  \n",
       "isco088150   Occupation, ISCO08 - With response: Textile, f...      Condition  \n",
       "regionDE128         Region - With response: Rhein-Neckar-Kreis           None  \n",
       "lnghom1SCO   Language most often spoken at home: first ment...      Condition  \n",
       "rshipa24     Second person in household: relationship to re...           None  \n",
       "c19spwrk3    Speak with people you work with in person, how...           None  \n",
       "regionES708                  Region - With response: Lanzarote      Condition  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "Survey_Overview_path = 'ESSQuestionData_withADICO.csv'  # Update this path accordingly\n",
    "Survey_Overview.to_csv(Survey_Overview_path, index=True)\n",
    "\n",
    "Survey_Overview.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Question Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Survey_Overview_path = 'ESSQuestionData_withADICO.csv'  # Update this path accordingly\n",
    "\n",
    "Survey_Overview_ADICO = pd.read_csv(Survey_Overview_path)\n",
    "\n",
    "Survey_Overview_ADICO.set_index('respid', inplace=True)\n",
    "Survey_Overview_ADICO.dropna(inplace=True)\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "Attributes = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Attribute', na=False), ['id', 'question_answers_combined']]\n",
    "Conditions = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Condition', na=False), ['id', 'question_answers_combined']]\n",
    "Aims = Survey_Overview_ADICO.loc[Survey_Overview_ADICO['ADICO_Category'].str.contains('Aim', na=False), ['id', 'question_answers_combined']]\n",
    "\n",
    "chosen_aims = Aims.sample(3) \n",
    "chosen_conditions = Conditions.sample(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question_answers_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atcherp4</th>\n",
       "      <td>atcherp</td>\n",
       "      <td>How emotionally attached to Europe - With resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stpldmi4</th>\n",
       "      <td>stpldmi</td>\n",
       "      <td>Important for democracy: government sticks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jbprtfp3</th>\n",
       "      <td>jbprtfp</td>\n",
       "      <td>Job prevents you from giving time to partner/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                          question_answers_combined\n",
       "respid                                                              \n",
       "atcherp4  atcherp  How emotionally attached to Europe - With resp...\n",
       "stpldmi4  stpldmi  Important for democracy: government sticks to ...\n",
       "jbprtfp3  jbprtfp  Job prevents you from giving time to partner/f..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_aims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m numerical_answers \u001b[38;5;241m=\u001b[39m numerical_answers\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aim \u001b[38;5;129;01min\u001b[39;00m chosen_aims:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m numerical_answers\u001b[38;5;241m.\u001b[39mcolumns: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     aimRow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Survey_Overview_ADICO\u001b[38;5;241m.\u001b[39mloc[aim[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion_answers_combined\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(aimRow)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# { \n",
    "#     \"alg\": \" HS512\"\n",
    "#     \"typ\": \"JWT\"\n",
    "# }\n",
    "numerical_answers = Survey_Responses.iloc[:,10:-34]\n",
    "\n",
    "# Try converting each column to numeric and coerce errors to NaN\n",
    "for column in numerical_answers.columns:\n",
    "    numerical_answers[column] = pd.to_numeric(numerical_answers[column], errors='coerce')\n",
    "\n",
    "# Drop columns that contain any NaN values (i.e., non-convertible columns)\n",
    "numerical_answers = numerical_answers.dropna(axis=1, how='any')\n",
    "\n",
    "for aim in chosen_aims:\n",
    "    if aim['id'] not in numerical_answers.columns: continue\n",
    "    aimRow = str(Survey_Overview_ADICO.loc[aim['id']]['question_answers_combined'])\n",
    "    print(aimRow)\n",
    "    class_names = Survey_Overview_ADICO['responseoptions']\n",
    "    feat_names = numerical_answers.loc[:, ~numerical_answers.columns.isin([aim])].columns\n",
    "    feature_descs = [Survey_Overview_ADICO[Survey_Overview_ADICO.index == feature]['question_answers_combined'].values for feature in feat_names if feature in list(Survey_Overview_ADICO.index)]\n",
    "\n",
    "    X = numerical_answers.loc[:, ~numerical_answers.columns.isin([aim])].values\n",
    "    Y = numerical_answers.loc[:, aim].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 100)\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = 'entropy', random_state=100, max_depth=1, min_samples_leaf=20)\n",
    "    clf_entropy.fit(X_train,y_train)\n",
    "    # Visualize the decision tree\n",
    "    plt.figure(figsize=(25,5))\n",
    "    plot_tree(clf_entropy, filled=True, feature_names=feature_descs, class_names = [str(item) for item in Survey_Responses[aim].unique()])\n",
    "    plt.show()\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    print((\"Accuracy is\"),accuracy_score(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Survey_Responses.loc[:, 'prtclbhr'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
