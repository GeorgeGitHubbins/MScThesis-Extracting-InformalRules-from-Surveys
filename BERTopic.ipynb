{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model, nr_topics=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "def replace_not_numbered(row):\n",
    "    if row[\"Question number\\n (Questionnaire file)\"] == \"not numbered\":\n",
    "        return row[\"Variable Label\\n (Data files)\"]\n",
    "    else:\n",
    "        return row[\"Question number\\n (Questionnaire file)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_questions  = pd.read_excel('Survey Questions Overview.xlsx', sheet_name='Wave 1', engine='openpyxl')\n",
    "# Clean the survey questions dataframe to make it more usable for mapping\n",
    "# Fill forward non-null ADICO Category values to apply them to all relevant rows, Specify the columns to forward fill excluding \"Values\" and \"Value labels\"\n",
    "columns_to_ffill = [col for col in survey_questions.columns if col not in [\"Values\", \"Value labels\"]]\n",
    "\n",
    "# Forward fill the specified columns\n",
    "survey_questions[columns_to_ffill] = survey_questions[columns_to_ffill].ffill()\n",
    "\n",
    "\n",
    "# Apply the function to replace \"not numbered\" with the value in \"Variable Label\"\n",
    "survey_questions[\"Question number\\n (Questionnaire file)\"] = survey_questions.apply(replace_not_numbered, axis=1)\n",
    "\n",
    "\n",
    "# Set the index to {value of \"Question number\\n (Questionnaire file)\"} + \"_\" + {str(value of \"Values\")}\n",
    "survey_questions.set_index(survey_questions[\"Variable Label\\n (Data files)\"] + \"_\" + survey_questions[\"Values\"].astype(str), inplace=True)\n",
    "\n",
    "question_answers_list = []\n",
    "# Define a function to create the combined string\n",
    "def combine_description_and_labels(group, question_answers_list, qnum):\n",
    "    question_subset = survey_questions[survey_questions[\"Question number\\n (Questionnaire file)\"] == group[\"Question number\\n (Questionnaire file)\"].iloc[0]]\n",
    "    # Check if it's the first row instance with the current \"Question number\\n (Questionnaire file)\" column value\n",
    "    first_instance_index = question_subset[question_subset.duplicated(subset=[\"Question number\\n (Questionnaire file)\"], keep=\"first\")].index\n",
    "    combined_string = \"\"\n",
    "    if first_instance_index.size != 0:\n",
    "        first_description = question_subset[\"Description\"].iloc[0]\n",
    "        if first_description != group[\"Description\"].iloc[0]:\n",
    "         # If not the first instance, start with the first instance's \"Description\" column value\n",
    "            combined_string += \" \" + first_description\n",
    "    # Concatenate the current row's \"Description\" and all \"Value labels\" values\n",
    "    combined_string += str(group[\"Description\"].iloc[0])# + \" \" + \"; \".join(group[\"Value labels\"].astype(str)))\n",
    "    question_answers_list = question_answers_list + [combined_string] * group.shape[0]  # Extend the list with the combined strings\n",
    "    return question_answers_list\n",
    "\n",
    "# Group by \"Variable Label\\n (Data files)\" and apply the function to create the combined string\n",
    "for group in survey_questions.groupby(\"Variable Label\\n (Data files)\",sort=False):\n",
    "    question_answers_list = combine_description_and_labels(group[1], question_answers_list, group[1][\"Question number\\n (Questionnaire file)\"].iloc[0])\n",
    "survey_questions[\"question_answers_combined\"] = question_answers_list\n",
    "\n",
    "survey_questions.drop(\"ID_nan\", inplace=True)\n",
    "survey_questions.drop_duplicates(inplace=True)\n",
    "# Drop rows with NaN values in the \"Values\" column\n",
    "survey_questions.dropna(subset=[\"Values\"], inplace=True)\n",
    "\n",
    "# Since the dataset has multiple rows per question for different value labels, we'll create a unique mapping\n",
    "# Create the new mapping dictionary\n",
    "question_adico_mapping = survey_questions[['question_answers_combined','ADICO Category',\"Variable Label\\n (Data files)\"]].drop_duplicates().set_index('question_answers_combined')['ADICO Category']\n",
    "\n",
    "\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "attributes = [k for k, v in question_adico_mapping.items() if 'Attribute' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "conditions = [k for k, v in question_adico_mapping.items() if 'Condition' in str(v) or 'Aim/Condition' in str(v) or 'Attribute/Condition' in str(v)]\n",
    "aims = [k for k, v in question_adico_mapping.items() if 'Aim' in str(v) or 'Aim/Condition' in str(v)]\n",
    "\n",
    "\n",
    "# Since the dataset has multiple rows per question for different value labels, we'll create a unique mapping\n",
    "# Create the new mapping dictionary\n",
    "question_adico_mapping = survey_questions[['question_answers_combined','ADICO Category',\"Variable Label\\n (Data files)\"]].drop_duplicates().set_index('question_answers_combined')\n",
    "\n",
    "# Filter out questions that are categorized as Attributes, Conditions, or Aims for clarity in analysis\n",
    "Attcons = survey_questions[survey_questions['ADICO Category'].isin([\"Attribute\", \"Condition\",'Aim/Condition', \"Attribute/Condition\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_csv(\"dataverse_files\\Wave1\\SCALAR_Coastal_Longitudinal_Study_Wave_1_NL.csv\").set_index(\"ID\")\n",
    "\n",
    "# Convert the numerical values in survey_questions to integers\n",
    "Attcons[\"Values\"] = Attcons[\"Values\"].astype(int)\n",
    "\n",
    "# Create a mapping dictionary\n",
    "mapping_dict = dict(zip(zip(Attcons[\"Variable Label\\n (Data files)\"], Attcons[\"Values\"]), Attcons[\"Value labels\"]))\n",
    "\n",
    "for column in survey_data.columns:\n",
    "    if column in Attcons[\"Variable Label\\n (Data files)\"].unique():\n",
    "        try:\n",
    "            # Map numerical values to string labels using the created dictionary\n",
    "            survey_data[column] = survey_data[column].astype(int)  # Ensure Q0_gender is of integer type\n",
    "            survey_data[column] = survey_data[column].map(lambda x: mapping_dict.get((column, x)))\n",
    "        except: \"not suitable column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data_list = []\n",
    "for column in survey_data.columns:\n",
    "    try:\n",
    "        survey_data_list += (survey_questions[survey_questions['Variable Label\\n (Data files)'] == column]['Description'].iat[0] + \" Given answer: \" + survey_data[column].astype(str)).to_list() \n",
    "    except: \"not str\"\n",
    "\n",
    "# Fit the BERTopic model\n",
    "topics, _ = topic_model.fit_transform(survey_data_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>92</td>\n",
       "      <td>-1_leave_pipes_antibackflow_valves</td>\n",
       "      <td>[leave, pipes, antibackflow, valves, cheap, di...</td>\n",
       "      <td>[Installing anti-backflow valves on pipes Give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1732</td>\n",
       "      <td>0_given_answer_flood_water</td>\n",
       "      <td>[given, answer, flood, water, andor, measure, ...</td>\n",
       "      <td>[Raising the level of the ground floor above t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>530</td>\n",
       "      <td>1_household_savings_answer_support</td>\n",
       "      <td>[household, savings, answer, support, given, c...</td>\n",
       "      <td>[How does your current TOTAL household savings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>2_yes_given_answer_disabled</td>\n",
       "      <td>[yes, given, answer, disabled, parent, physica...</td>\n",
       "      <td>[No Given answer: Yes, No Given answer: Yes, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>3_media_climate_change_reasons</td>\n",
       "      <td>[media, climate, change, reasons, social, foll...</td>\n",
       "      <td>[There is a lot of discussion about global cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>4_community_group_active_member</td>\n",
       "      <td>[community, group, active, member, petitioning...</td>\n",
       "      <td>[Being an active member in a community group a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>5_antibackflow_valves_pipes_installing</td>\n",
       "      <td>[antibackflow, valves, pipes, installing, stru...</td>\n",
       "      <td>[Installing anti-backflow valves on pipes Give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6_identify_gender_age_female</td>\n",
       "      <td>[identify, gender, age, female, male, 5564, 65...</td>\n",
       "      <td>[What gender do you identify with? Given answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7_feeling_city_attachment_area</td>\n",
       "      <td>[feeling, city, attachment, area, given, answe...</td>\n",
       "      <td>[Feeling of attachment to the city/ area Given...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                    Name  \\\n",
       "0     -1     92      -1_leave_pipes_antibackflow_valves   \n",
       "1      0   1732              0_given_answer_flood_water   \n",
       "2      1    530      1_household_savings_answer_support   \n",
       "3      2    320             2_yes_given_answer_disabled   \n",
       "4      3    220          3_media_climate_change_reasons   \n",
       "5      4    187         4_community_group_active_member   \n",
       "6      5     59  5_antibackflow_valves_pipes_installing   \n",
       "7      6     40            6_identify_gender_age_female   \n",
       "8      7     20          7_feeling_city_attachment_area   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [leave, pipes, antibackflow, valves, cheap, di...   \n",
       "1  [given, answer, flood, water, andor, measure, ...   \n",
       "2  [household, savings, answer, support, given, c...   \n",
       "3  [yes, given, answer, disabled, parent, physica...   \n",
       "4  [media, climate, change, reasons, social, foll...   \n",
       "5  [community, group, active, member, petitioning...   \n",
       "6  [antibackflow, valves, pipes, installing, stru...   \n",
       "7  [identify, gender, age, female, male, 5564, 65...   \n",
       "8  [feeling, city, attachment, area, given, answe...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Installing anti-backflow valves on pipes Give...  \n",
       "1  [Raising the level of the ground floor above t...  \n",
       "2  [How does your current TOTAL household savings...  \n",
       "3  [No Given answer: Yes, No Given answer: Yes, N...  \n",
       "4  [There is a lot of discussion about global cli...  \n",
       "5  [Being an active member in a community group a...  \n",
       "6  [Installing anti-backflow valves on pipes Give...  \n",
       "7  [What gender do you identify with? Given answe...  \n",
       "8  [Feeling of attachment to the city/ area Given...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'leave pipes antibackflow valves cheap difficult expensive given answer installing',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.43793100118637085, 0.2904495894908905, 0.27161943912506104]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'given answer flood water andor measure intend home implement level',\n",
       " 'labels': ['Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.37821295857429504, 0.34297946095466614, 0.27880755066871643]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'household savings answer support given current income total does years',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.6098644733428955, 0.1969531923532486, 0.19318237900733948]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'yes given answer disabled parent physically insurance groups selfemployed mentally',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.5299656987190247, 0.24919234216213226, 0.22084201872348785]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'media climate change reasons social following instagram facebook weibo general',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.4422215521335602, 0.3074537515640259, 0.25032469630241394]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'community group active member petitioning representative public aimed making safer',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.3877420127391815, 0.32883626222610474, 0.28342175483703613]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'antibackflow valves pipes installing structural implement intend measure given answer',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.40084969997406006, 0.3003448247909546, 0.2988055348396301]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'identify gender age female male 5564 65 4554 given answer',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.5957229137420654, 0.21319955587387085, 0.1910775750875473]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'feeling city attachment area given answer    ',\n",
       " 'labels': ['Spatial: Where, Location or Direction',\n",
       "  'Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.41320911049842834, 0.4000754654407501, 0.18671546876430511]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "for Topic in topic_model.get_topic_info()['Topic']:\n",
    "    # A selected topic representation\n",
    "    # 'god jesus atheists atheism belief atheist believe exist beliefs existence'\n",
    "    sequence_to_classify =  \" \".join([word for word, _ in topic_model.get_topic(Topic)])\n",
    "\n",
    "    # Our set of potential topic labels\n",
    "    candidate_labels = [\n",
    "    'Spatial: Where, Location or Direction',\n",
    "    'Temporal: When, Point in time or Time Frame',\n",
    "    'Procedural: Why, How, Activity or Topical Realm'\n",
    "]\n",
    "    display(classifier(sequence_to_classify, candidate_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': ' Please indicate if you have already implemented any of these nonstructural measures or if you intend to do so in the futureKeeping a working flashlight and/or a battery-operated radio and/or emergency kit in a convenient location',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.4986564815044403, 0.3828352093696594, 0.11850827187299728]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' When you think in terms of your income and your other expenses, do you believe that implementing or paying someone to implement this structural measure would be cheap or expensive?Raising the electricity meter above the most likely flood level or on an upper floor',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.3851831555366516, 0.3485691249370575, 0.2662477195262909]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' Do you have the ability to undertake the nonstructural measure either yourself or by paying a professional to do so?Buying a spare power generator to power your home',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.5999974608421326, 0.2967781722545624, 0.10322435945272446]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' Please indicate if you have already implemented any of these nonstructural measures or if you intend to do so in the futurePurchasing sandbags, or other water barriers',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.6556395888328552, 0.23041008412837982, 0.11395033448934555]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'What is the highest level of education you have completed?',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.41260287165641785, 0.3836902379989624, 0.20370693504810333]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'There is a lot of discussion about global climate change and its connection to extreme weather events. Which of the following statements do you most agree with?',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.5311707258224487, 0.304313600063324, 0.1645156592130661]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' Employer typeIndustry type',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.43355804681777954, 0.32681524753570557, 0.23962673544883728]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': ' Other than the government, in the event of a flood, are there other sources that you would expect to provide you with compensation? Multiple answers possibleMy insurance',\n",
       " 'labels': ['Procedural: Why, How, Activity or Topical Realm',\n",
       "  'Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction'],\n",
       " 'scores': [0.4259442090988159, 0.3939427435398102, 0.1801130473613739]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"Roughly what percentage of your household's monthly income is due to your job?\",\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.5354028344154358, 0.24290350079536438, 0.22169364988803864]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'What is the highest level of education you have completed?',\n",
       " 'labels': ['Temporal: When, Point in time or Time Frame',\n",
       "  'Spatial: Where, Location or Direction',\n",
       "  'Procedural: Why, How, Activity or Topical Realm'],\n",
       " 'scores': [0.41260287165641785, 0.3836902379989624, 0.20370693504810333]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define the candidate labels\n",
    "candidate_labels = [\n",
    "    'Spatial: Where, Location or Direction',\n",
    "    'Temporal: When, Point in time or Time Frame',\n",
    "    'Procedural: Why, How, Activity or Topical Realm'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store the predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Loop through each question in the 'Description' column of Attcons\n",
    "for question in Attcons['question_answers_combined'].sample(n=10):\n",
    "    # Classify the question using zero-shot classification\n",
    "    classification_result = classifier(question, candidate_labels)\n",
    "    display(classification_result)\n",
    "#     # Get the label with the highest score\n",
    "#     highest_score_index = np.argmax(classification_result[\"scores\"])\n",
    "#     predicted_label = classification_result[\"labels\"][highest_score_index]\n",
    "    \n",
    "#     # Append the predicted label to the list\n",
    "#     predicted_labels.append(predicted_label)\n",
    "\n",
    "# # Add the predicted labels as a new column to the Attcons DataFrame\n",
    "# Attcons[\"Predicted_Label\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define the candidate labels\n",
    "candidate_labels = {\n",
    "    \"Aim: Actions performed or intended by the responder\": \"Aim\",\n",
    "    \"Condition: External factors influencing the responder's actions such as money, living conditions, time.\": \"Condition\"\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "SampleAttcons = Attcons.sample(n=10)\n",
    "\n",
    "# Loop through each question in the 'Description' column of Attcons\n",
    "for question in SampleAttcons['question_answers_combined']:\n",
    "    # Classify the question using zero-shot classification\n",
    "    classification_result = classifier(question, list(candidate_labels.keys()))\n",
    "    # display(classification_result)\n",
    "    # Get the label with the highest score\n",
    "    highest_score_index = np.argmax(classification_result[\"scores\"])\n",
    "    predicted_label = classification_result[\"labels\"][highest_score_index]\n",
    "    \n",
    "    # Append the predicted label to the list\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Add the predicted labels as a new column to the Attcons DataFrame\n",
    "SampleAttcons[\"Predicted_Label\"] = predicted_labels\n",
    "\n",
    "# Replace the values in the DataFrame column\n",
    "SampleAttcons['Predicted_Label'] = SampleAttcons['Predicted_Label'].replace(candidate_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coolg\\AppData\\Local\\Temp\\ipykernel_12964\\1781282950.py:35: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarities = np.array([[np.dot(question_embedding, category_embedding) /\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained word embeddings model (you can use any suitable model)\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define the categories\n",
    "categories = [\n",
    "    'Spatial: Where, Location or Direction',\n",
    "    'Temporal: When, Point in time or Time Frame',\n",
    "    'Procedural: Why, How, Activity or Topical Realm'\n",
    "]\n",
    "\n",
    "# Calculate the average word embedding for each category\n",
    "category_embeddings = {}\n",
    "for description in categories:\n",
    "    category_doc = nlp(description)\n",
    "    vectors = [token.vector for token in category_doc if token.has_vector]\n",
    "    if vectors:\n",
    "        category_embedding = np.mean(vectors, axis=0)\n",
    "        category_embeddings[description] = category_embedding\n",
    "    else:\n",
    "        category_embeddings[description] = np.zeros((nlp.vocab.vectors_length,))\n",
    "\n",
    "# Process each survey question and calculate its average word embedding\n",
    "word_embeddings = []\n",
    "for question in Attcons['question_answers_combined']:\n",
    "    doc = nlp(question)\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if vectors:\n",
    "        question_embedding = np.mean(vectors, axis=0)\n",
    "        word_embeddings.append(question_embedding)\n",
    "    else:\n",
    "        # Handle the case where no tokens in the question have vectors\n",
    "        word_embeddings.append(np.zeros((nlp.vocab.vectors_length,)))\n",
    "\n",
    "# Calculate the similarity between each question embedding and each category embedding\n",
    "similarities = np.array([[np.dot(question_embedding, category_embedding) /\n",
    "                          (np.linalg.norm(question_embedding) * np.linalg.norm(category_embedding))\n",
    "                          for category_embedding in category_embeddings.values()]\n",
    "                         for question_embedding in word_embeddings])\n",
    "\n",
    "# Assign each question to the category with the highest similarity score\n",
    "question_categories = [categories[np.argmax(similarity)] for similarity in similarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADICO Category</th>\n",
       "      <th>Question number\\n (Questionnaire file)</th>\n",
       "      <th>Variable Label\\n (Data files)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Values</th>\n",
       "      <th>Value labels</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q0_age_1.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Age</td>\n",
       "      <td>1</td>\n",
       "      <td>16-24</td>\n",
       "      <td>Age</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q0_age_2.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Age</td>\n",
       "      <td>2</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Age</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q0_age_3.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Age</td>\n",
       "      <td>3</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Age</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q0_age_4.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Age</td>\n",
       "      <td>4</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Age</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q0_age_5.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Q0_age</td>\n",
       "      <td>Age</td>\n",
       "      <td>5</td>\n",
       "      <td>55-64</td>\n",
       "      <td>Age</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q60a_parent_0.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q60a</td>\n",
       "      <td>Q60a_parent</td>\n",
       "      <td>Are you the parent or guardian of any children...</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Are you the parent or guardian of any children...</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q60a_parent_1.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q60a</td>\n",
       "      <td>Q60a_parent</td>\n",
       "      <td>Are you the parent or guardian of any children...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Are you the parent or guardian of any children...</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61_single_parent_0.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q61</td>\n",
       "      <td>Q61_single_parent</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>Procedural: Why, How, Activity or Topical Realm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61_single_parent_1.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q61</td>\n",
       "      <td>Q61_single_parent</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>Procedural: Why, How, Activity or Topical Realm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61_single_parent_99.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q61</td>\n",
       "      <td>Q61_single_parent</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>99</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Are you a single parent?</td>\n",
       "      <td>Procedural: Why, How, Activity or Topical Realm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>939 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ADICO Category Question number\\n (Questionnaire file)  \\\n",
       "Q0_age_1.0                  Attribute                                 Q0_age   \n",
       "Q0_age_2.0                  Attribute                                 Q0_age   \n",
       "Q0_age_3.0                  Attribute                                 Q0_age   \n",
       "Q0_age_4.0                  Attribute                                 Q0_age   \n",
       "Q0_age_5.0                  Attribute                                 Q0_age   \n",
       "...                               ...                                    ...   \n",
       "Q60a_parent_0.0             Condition                                   Q60a   \n",
       "Q60a_parent_1.0             Condition                                   Q60a   \n",
       "Q61_single_parent_0.0       Condition                                    Q61   \n",
       "Q61_single_parent_1.0       Condition                                    Q61   \n",
       "Q61_single_parent_99.0      Condition                                    Q61   \n",
       "\n",
       "                       Variable Label\\n (Data files)  \\\n",
       "Q0_age_1.0                                    Q0_age   \n",
       "Q0_age_2.0                                    Q0_age   \n",
       "Q0_age_3.0                                    Q0_age   \n",
       "Q0_age_4.0                                    Q0_age   \n",
       "Q0_age_5.0                                    Q0_age   \n",
       "...                                              ...   \n",
       "Q60a_parent_0.0                          Q60a_parent   \n",
       "Q60a_parent_1.0                          Q60a_parent   \n",
       "Q61_single_parent_0.0              Q61_single_parent   \n",
       "Q61_single_parent_1.0              Q61_single_parent   \n",
       "Q61_single_parent_99.0             Q61_single_parent   \n",
       "\n",
       "                                                              Description  \\\n",
       "Q0_age_1.0                                                            Age   \n",
       "Q0_age_2.0                                                            Age   \n",
       "Q0_age_3.0                                                            Age   \n",
       "Q0_age_4.0                                                            Age   \n",
       "Q0_age_5.0                                                            Age   \n",
       "...                                                                   ...   \n",
       "Q60a_parent_0.0         Are you the parent or guardian of any children...   \n",
       "Q60a_parent_1.0         Are you the parent or guardian of any children...   \n",
       "Q61_single_parent_0.0                            Are you a single parent?   \n",
       "Q61_single_parent_1.0                            Are you a single parent?   \n",
       "Q61_single_parent_99.0                           Are you a single parent?   \n",
       "\n",
       "                        Values       Value labels  \\\n",
       "Q0_age_1.0                   1              16-24   \n",
       "Q0_age_2.0                   2              25-34   \n",
       "Q0_age_3.0                   3              35-44   \n",
       "Q0_age_4.0                   4              45-54   \n",
       "Q0_age_5.0                   5              55-64   \n",
       "...                        ...                ...   \n",
       "Q60a_parent_0.0              0                 No   \n",
       "Q60a_parent_1.0              1                Yes   \n",
       "Q61_single_parent_0.0        0                 No   \n",
       "Q61_single_parent_1.0        1                Yes   \n",
       "Q61_single_parent_99.0      99  Prefer not to say   \n",
       "\n",
       "                                                question_answers_combined  \\\n",
       "Q0_age_1.0                                                            Age   \n",
       "Q0_age_2.0                                                            Age   \n",
       "Q0_age_3.0                                                            Age   \n",
       "Q0_age_4.0                                                            Age   \n",
       "Q0_age_5.0                                                            Age   \n",
       "...                                                                   ...   \n",
       "Q60a_parent_0.0         Are you the parent or guardian of any children...   \n",
       "Q60a_parent_1.0         Are you the parent or guardian of any children...   \n",
       "Q61_single_parent_0.0                            Are you a single parent?   \n",
       "Q61_single_parent_1.0                            Are you a single parent?   \n",
       "Q61_single_parent_99.0                           Are you a single parent?   \n",
       "\n",
       "                                                               category  \n",
       "Q0_age_1.0                  Temporal: When, Point in time or Time Frame  \n",
       "Q0_age_2.0                  Temporal: When, Point in time or Time Frame  \n",
       "Q0_age_3.0                  Temporal: When, Point in time or Time Frame  \n",
       "Q0_age_4.0                  Temporal: When, Point in time or Time Frame  \n",
       "Q0_age_5.0                  Temporal: When, Point in time or Time Frame  \n",
       "...                                                                 ...  \n",
       "Q60a_parent_0.0                   Spatial: Where, Location or Direction  \n",
       "Q60a_parent_1.0                   Spatial: Where, Location or Direction  \n",
       "Q61_single_parent_0.0   Procedural: Why, How, Activity or Topical Realm  \n",
       "Q61_single_parent_1.0   Procedural: Why, How, Activity or Topical Realm  \n",
       "Q61_single_parent_99.0  Procedural: Why, How, Activity or Topical Realm  \n",
       "\n",
       "[939 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attcons['category'] = question_categories\n",
    "# question_categories\n",
    "Attcons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coolg\\AppData\\Local\\Temp\\ipykernel_12964\\3540551059.py:36: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarities = np.array([[np.dot(question_embedding, category_embedding) /\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load pre-trained word embeddings model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define the candidate labels\n",
    "candidate_labels = {\n",
    "    \"Aim: Actions performed or intended by the responder\": \"Aim\",\n",
    "    \"Condition: External factors influencing the responder's actions such as, age, money, living conditions, time.\": \"Condition\"\n",
    "}\n",
    "\n",
    "# Calculate the average word embedding for each category\n",
    "category_embeddings = {}\n",
    "for label, description in candidate_labels.items():\n",
    "    category_doc = nlp(label)\n",
    "    vectors = [token.vector for token in category_doc if token.has_vector]\n",
    "    if vectors:\n",
    "        category_embedding = np.mean(vectors, axis=0)\n",
    "        category_embeddings[description] = category_embedding\n",
    "    else:\n",
    "        category_embeddings[description] = np.zeros((nlp.vocab.vectors_length,))\n",
    "\n",
    "# Process each survey question and calculate its average word embedding\n",
    "word_embeddings = []\n",
    "for question in Attcons['question_answers_combined']:\n",
    "    doc = nlp(question)\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    if vectors:\n",
    "        question_embedding = np.mean(vectors, axis=0)\n",
    "        word_embeddings.append(question_embedding)\n",
    "    else:\n",
    "        # Handle the case where no tokens in the question have vectors\n",
    "        word_embeddings.append(np.zeros((nlp.vocab.vectors_length,)))\n",
    "\n",
    "# Calculate the similarity between each question embedding and each category embedding\n",
    "similarities = np.array([[np.dot(question_embedding, category_embedding) /\n",
    "                          (np.linalg.norm(question_embedding) * np.linalg.norm(category_embedding))\n",
    "                          for category_embedding in category_embeddings.values()]\n",
    "                         for question_embedding in word_embeddings])\n",
    "\n",
    "# Assign each question to the category with the highest similarity score\n",
    "categories = list(candidate_labels.values())  # Ensure this matches the keys used in similarities calculation\n",
    "question_categories = [categories[np.argmax(sim)] for sim in similarities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADICO Category</th>\n",
       "      <th>Question number\\n (Questionnaire file)</th>\n",
       "      <th>Variable Label\\n (Data files)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Values</th>\n",
       "      <th>Value labels</th>\n",
       "      <th>question_answers_combined</th>\n",
       "      <th>category</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R1c_perc_cost_SM7_4.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q35c</td>\n",
       "      <td>R1c_perc_cost_SM7</td>\n",
       "      <td>Fixing water barriers (e.g. water-proof baseme...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>When you think in terms of your income and yo...</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q0_employment_CN_3.0</th>\n",
       "      <td>Attribute</td>\n",
       "      <td>Q0_employment_CN</td>\n",
       "      <td>Q0_employment_CN</td>\n",
       "      <td>Employment status</td>\n",
       "      <td>3</td>\n",
       "      <td>Working part time (Less than 8 hours a week)</td>\n",
       "      <td>Employment status</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q31b_social_media_trust_3.0</th>\n",
       "      <td>Aim/Condition</td>\n",
       "      <td>Q31</td>\n",
       "      <td>Q31b_social_media_trust</td>\n",
       "      <td>From social media (i.e. Facebook, Instagram, W...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>To what extent, if at all, do you trust infor...</td>\n",
       "      <td>Procedural: Why, How, Activity or Topical Realm</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q47a_employer_type_CN_ID_2.0</th>\n",
       "      <td>Attribute/Condition</td>\n",
       "      <td>Q47a</td>\n",
       "      <td>Q47a_employer_type_CN_ID</td>\n",
       "      <td>Employer type</td>\n",
       "      <td>2</td>\n",
       "      <td>Public sector – government owned or funded (e....</td>\n",
       "      <td>Employer type</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q57_hh_size_US_7.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q57</td>\n",
       "      <td>Q57_hh_size_US</td>\n",
       "      <td>Household size</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Household size</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q11a_hazard_type8_0.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q11a</td>\n",
       "      <td>Q11a_hazard_type8</td>\n",
       "      <td>Tsunamis</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>HurricanesTsunamis</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q50_employer_size_12.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q50</td>\n",
       "      <td>Q50_employer_size</td>\n",
       "      <td>Business size</td>\n",
       "      <td>12</td>\n",
       "      <td>1,000 or more</td>\n",
       "      <td>Business size</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R02_perc_prob_2.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q23</td>\n",
       "      <td>R02_perc_prob</td>\n",
       "      <td>How often do you think a flood occurs on the p...</td>\n",
       "      <td>2</td>\n",
       "      <td>Less often than 1 in 500 years</td>\n",
       "      <td>How often do you think a flood occurs on the p...</td>\n",
       "      <td>Spatial: Where, Location or Direction</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q53_income_CN_99.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q53</td>\n",
       "      <td>Q53_income_CN</td>\n",
       "      <td>What was your total family income from all sou...</td>\n",
       "      <td>99</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>What was your total family income from all sou...</td>\n",
       "      <td>Temporal: When, Point in time or Time Frame</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R1c_perc_cost_NM3_2.0</th>\n",
       "      <td>Condition</td>\n",
       "      <td>Q39c</td>\n",
       "      <td>R1c_perc_cost_NM3</td>\n",
       "      <td>Buying a spare power generator to power your home</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>When you think in terms of your income and yo...</td>\n",
       "      <td>Procedural: Why, How, Activity or Topical Realm</td>\n",
       "      <td>Condition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ADICO Category  \\\n",
       "R1c_perc_cost_SM7_4.0                   Condition   \n",
       "Q0_employment_CN_3.0                    Attribute   \n",
       "Q31b_social_media_trust_3.0         Aim/Condition   \n",
       "Q47a_employer_type_CN_ID_2.0  Attribute/Condition   \n",
       "Q57_hh_size_US_7.0                      Condition   \n",
       "Q11a_hazard_type8_0.0                   Condition   \n",
       "Q50_employer_size_12.0                  Condition   \n",
       "R02_perc_prob_2.0                       Condition   \n",
       "Q53_income_CN_99.0                      Condition   \n",
       "R1c_perc_cost_NM3_2.0                   Condition   \n",
       "\n",
       "                             Question number\\n (Questionnaire file)  \\\n",
       "R1c_perc_cost_SM7_4.0                                          Q35c   \n",
       "Q0_employment_CN_3.0                               Q0_employment_CN   \n",
       "Q31b_social_media_trust_3.0                                     Q31   \n",
       "Q47a_employer_type_CN_ID_2.0                                   Q47a   \n",
       "Q57_hh_size_US_7.0                                              Q57   \n",
       "Q11a_hazard_type8_0.0                                          Q11a   \n",
       "Q50_employer_size_12.0                                          Q50   \n",
       "R02_perc_prob_2.0                                               Q23   \n",
       "Q53_income_CN_99.0                                              Q53   \n",
       "R1c_perc_cost_NM3_2.0                                          Q39c   \n",
       "\n",
       "                             Variable Label\\n (Data files)  \\\n",
       "R1c_perc_cost_SM7_4.0                    R1c_perc_cost_SM7   \n",
       "Q0_employment_CN_3.0                      Q0_employment_CN   \n",
       "Q31b_social_media_trust_3.0        Q31b_social_media_trust   \n",
       "Q47a_employer_type_CN_ID_2.0      Q47a_employer_type_CN_ID   \n",
       "Q57_hh_size_US_7.0                          Q57_hh_size_US   \n",
       "Q11a_hazard_type8_0.0                    Q11a_hazard_type8   \n",
       "Q50_employer_size_12.0                   Q50_employer_size   \n",
       "R02_perc_prob_2.0                            R02_perc_prob   \n",
       "Q53_income_CN_99.0                           Q53_income_CN   \n",
       "R1c_perc_cost_NM3_2.0                    R1c_perc_cost_NM3   \n",
       "\n",
       "                                                                    Description  \\\n",
       "R1c_perc_cost_SM7_4.0         Fixing water barriers (e.g. water-proof baseme...   \n",
       "Q0_employment_CN_3.0                                          Employment status   \n",
       "Q31b_social_media_trust_3.0   From social media (i.e. Facebook, Instagram, W...   \n",
       "Q47a_employer_type_CN_ID_2.0                                      Employer type   \n",
       "Q57_hh_size_US_7.0                                               Household size   \n",
       "Q11a_hazard_type8_0.0                                                  Tsunamis   \n",
       "Q50_employer_size_12.0                                            Business size   \n",
       "R02_perc_prob_2.0             How often do you think a flood occurs on the p...   \n",
       "Q53_income_CN_99.0            What was your total family income from all sou...   \n",
       "R1c_perc_cost_NM3_2.0         Buying a spare power generator to power your home   \n",
       "\n",
       "                              Values  \\\n",
       "R1c_perc_cost_SM7_4.0              4   \n",
       "Q0_employment_CN_3.0               3   \n",
       "Q31b_social_media_trust_3.0        3   \n",
       "Q47a_employer_type_CN_ID_2.0       2   \n",
       "Q57_hh_size_US_7.0                 7   \n",
       "Q11a_hazard_type8_0.0              0   \n",
       "Q50_employer_size_12.0            12   \n",
       "R02_perc_prob_2.0                  2   \n",
       "Q53_income_CN_99.0                99   \n",
       "R1c_perc_cost_NM3_2.0              2   \n",
       "\n",
       "                                                                   Value labels  \\\n",
       "R1c_perc_cost_SM7_4.0                                                         4   \n",
       "Q0_employment_CN_3.0               Working part time (Less than 8 hours a week)   \n",
       "Q31b_social_media_trust_3.0                                                   3   \n",
       "Q47a_employer_type_CN_ID_2.0  Public sector – government owned or funded (e....   \n",
       "Q57_hh_size_US_7.0                                                            7   \n",
       "Q11a_hazard_type8_0.0                                                        No   \n",
       "Q50_employer_size_12.0                                            1,000 or more   \n",
       "R02_perc_prob_2.0                                Less often than 1 in 500 years   \n",
       "Q53_income_CN_99.0                                            Prefer not to say   \n",
       "R1c_perc_cost_NM3_2.0                                                         2   \n",
       "\n",
       "                                                      question_answers_combined  \\\n",
       "R1c_perc_cost_SM7_4.0          When you think in terms of your income and yo...   \n",
       "Q0_employment_CN_3.0                                          Employment status   \n",
       "Q31b_social_media_trust_3.0    To what extent, if at all, do you trust infor...   \n",
       "Q47a_employer_type_CN_ID_2.0                                      Employer type   \n",
       "Q57_hh_size_US_7.0                                               Household size   \n",
       "Q11a_hazard_type8_0.0                                        HurricanesTsunamis   \n",
       "Q50_employer_size_12.0                                            Business size   \n",
       "R02_perc_prob_2.0             How often do you think a flood occurs on the p...   \n",
       "Q53_income_CN_99.0            What was your total family income from all sou...   \n",
       "R1c_perc_cost_NM3_2.0          When you think in terms of your income and yo...   \n",
       "\n",
       "                                                                     category  \\\n",
       "R1c_perc_cost_SM7_4.0                   Spatial: Where, Location or Direction   \n",
       "Q0_employment_CN_3.0                    Spatial: Where, Location or Direction   \n",
       "Q31b_social_media_trust_3.0   Procedural: Why, How, Activity or Topical Realm   \n",
       "Q47a_employer_type_CN_ID_2.0            Spatial: Where, Location or Direction   \n",
       "Q57_hh_size_US_7.0                Temporal: When, Point in time or Time Frame   \n",
       "Q11a_hazard_type8_0.0                   Spatial: Where, Location or Direction   \n",
       "Q50_employer_size_12.0                  Spatial: Where, Location or Direction   \n",
       "R02_perc_prob_2.0                       Spatial: Where, Location or Direction   \n",
       "Q53_income_CN_99.0                Temporal: When, Point in time or Time Frame   \n",
       "R1c_perc_cost_NM3_2.0         Procedural: Why, How, Activity or Topical Realm   \n",
       "\n",
       "                             Predicted_Label  \n",
       "R1c_perc_cost_SM7_4.0              Condition  \n",
       "Q0_employment_CN_3.0               Condition  \n",
       "Q31b_social_media_trust_3.0        Condition  \n",
       "Q47a_employer_type_CN_ID_2.0             Aim  \n",
       "Q57_hh_size_US_7.0                 Condition  \n",
       "Q11a_hazard_type8_0.0                    Aim  \n",
       "Q50_employer_size_12.0             Condition  \n",
       "R02_perc_prob_2.0                  Condition  \n",
       "Q53_income_CN_99.0                 Condition  \n",
       "R1c_perc_cost_NM3_2.0              Condition  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attcons['Predicted_Label'] = question_categories\n",
    "\n",
    "# question_categories\n",
    "Attcons.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m OPENAI_Key\n\u001b[0;32m      4\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m OPENAI_Key\n\u001b[1;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho won the world series in 2020?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe Los Angeles Dodgers won the World Series in 2020.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhere was it played?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1207\u001b[0m     )\n\u001b[1;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    972\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1021\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    972\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1021\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coolg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:988\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    985\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    987\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    991\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    992\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    995\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    996\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "OPENAI_Key = \"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\"\n",
    "import openai\n",
    "openai.api_key = OPENAI_Key\n",
    "OPENAI_API_KEY = OPENAI_Key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
